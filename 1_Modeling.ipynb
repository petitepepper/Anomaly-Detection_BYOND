{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bec5f4de",
   "metadata": {},
   "source": [
    "# 0. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04f86b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from joblib import dump\n",
    "\n",
    "# Isolation Forest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# VAE\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense, Lambda, Flatten, Reshape\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c0c0f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>cell_id</th>\n",
       "      <th>DL_TRAFFIC_VOLUME</th>\n",
       "      <th>UL_TRAFFIC_VOLUME</th>\n",
       "      <th>Inter_X2_based_HO_prep</th>\n",
       "      <th>VoLTE_total_traffic</th>\n",
       "      <th>INTRA_FREQ_HO_SR_RATIO</th>\n",
       "      <th>RRC_SR_RATIO</th>\n",
       "      <th>CELL_AVAILABILITY_RATIO</th>\n",
       "      <th>RACH_Stp_Completion_SR_RATIO</th>\n",
       "      <th>...</th>\n",
       "      <th>DCR_LTE_RATIO</th>\n",
       "      <th>CSSR_LTE_RATIO</th>\n",
       "      <th>LTE_INTER_ENODEB_HOSR_RATIO</th>\n",
       "      <th>E_UTRAN_Inter_Freq_HO_SR_RATIO</th>\n",
       "      <th>Inter_RAT_HO_SR_GERAN_SRVCC_RATIO</th>\n",
       "      <th>Inter_RAT_Total_HO_SR_RATIO</th>\n",
       "      <th>E_UTRAN_tot_HO_SR_inter_eNB_X2_RATIO</th>\n",
       "      <th>E_RAB_DR_RATIO</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>cell</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-05-09 00:00:00</td>\n",
       "      <td>2.226537e+17</td>\n",
       "      <td>3.779737e+10</td>\n",
       "      <td>3.947172e+09</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4727.0</td>\n",
       "      <td>0.809859</td>\n",
       "      <td>0.992427</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.962688</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001761</td>\n",
       "      <td>0.996041</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.770642</td>\n",
       "      <td>0.963636</td>\n",
       "      <td>0.963636</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.001761</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-05-09 01:00:00</td>\n",
       "      <td>2.226537e+17</td>\n",
       "      <td>3.684898e+10</td>\n",
       "      <td>4.088752e+09</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3076.0</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.993288</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.973207</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002468</td>\n",
       "      <td>0.995465</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.002468</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-05-09 02:00:00</td>\n",
       "      <td>2.226537e+17</td>\n",
       "      <td>3.292677e+10</td>\n",
       "      <td>5.016897e+09</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3501.0</td>\n",
       "      <td>0.938356</td>\n",
       "      <td>0.994664</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.966330</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003077</td>\n",
       "      <td>0.996044</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.931624</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.003077</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-05-09 03:00:00</td>\n",
       "      <td>2.226537e+17</td>\n",
       "      <td>3.021547e+10</td>\n",
       "      <td>5.139107e+09</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2275.0</td>\n",
       "      <td>0.860215</td>\n",
       "      <td>0.994819</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.943216</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001721</td>\n",
       "      <td>0.995920</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.816901</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.001721</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-05-09 04:00:00</td>\n",
       "      <td>2.226537e+17</td>\n",
       "      <td>3.082176e+10</td>\n",
       "      <td>4.250716e+09</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2178.0</td>\n",
       "      <td>0.840426</td>\n",
       "      <td>0.995952</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.936256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002213</td>\n",
       "      <td>0.995628</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.794521</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.002213</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 index       cell_id  DL_TRAFFIC_VOLUME  UL_TRAFFIC_VOLUME  \\\n",
       "0  2021-05-09 00:00:00  2.226537e+17       3.779737e+10       3.947172e+09   \n",
       "1  2021-05-09 01:00:00  2.226537e+17       3.684898e+10       4.088752e+09   \n",
       "2  2021-05-09 02:00:00  2.226537e+17       3.292677e+10       5.016897e+09   \n",
       "3  2021-05-09 03:00:00  2.226537e+17       3.021547e+10       5.139107e+09   \n",
       "4  2021-05-09 04:00:00  2.226537e+17       3.082176e+10       4.250716e+09   \n",
       "\n",
       "   Inter_X2_based_HO_prep  VoLTE_total_traffic  INTRA_FREQ_HO_SR_RATIO  \\\n",
       "0                    15.0               4727.0                0.809859   \n",
       "1                     6.0               3076.0                0.886792   \n",
       "2                     8.0               3501.0                0.938356   \n",
       "3                     9.0               2275.0                0.860215   \n",
       "4                    17.0               2178.0                0.840426   \n",
       "\n",
       "   RRC_SR_RATIO  CELL_AVAILABILITY_RATIO  RACH_Stp_Completion_SR_RATIO  ...  \\\n",
       "0      0.992427                      1.0                      0.962688  ...   \n",
       "1      0.993288                      1.0                      0.973207  ...   \n",
       "2      0.994664                      1.0                      0.966330  ...   \n",
       "3      0.994819                      1.0                      0.943216  ...   \n",
       "4      0.995952                      1.0                      0.936256  ...   \n",
       "\n",
       "   DCR_LTE_RATIO  CSSR_LTE_RATIO  LTE_INTER_ENODEB_HOSR_RATIO  \\\n",
       "0       0.001761        0.996041                     0.400000   \n",
       "1       0.002468        0.995465                     0.500000   \n",
       "2       0.003077        0.996044                     0.375000   \n",
       "3       0.001721        0.995920                     0.777778   \n",
       "4       0.002213        0.995628                     0.764706   \n",
       "\n",
       "   E_UTRAN_Inter_Freq_HO_SR_RATIO  Inter_RAT_HO_SR_GERAN_SRVCC_RATIO  \\\n",
       "0                        0.770642                           0.963636   \n",
       "1                        0.842105                           1.000000   \n",
       "2                        0.931624                           1.000000   \n",
       "3                        0.816901                           0.947368   \n",
       "4                        0.794521                           1.000000   \n",
       "\n",
       "   Inter_RAT_Total_HO_SR_RATIO  E_UTRAN_tot_HO_SR_inter_eNB_X2_RATIO  \\\n",
       "0                     0.963636                              0.400000   \n",
       "1                     1.000000                              0.500000   \n",
       "2                     0.966667                              0.375000   \n",
       "3                     0.947368                              0.777778   \n",
       "4                     1.000000                              0.764706   \n",
       "\n",
       "   E_RAB_DR_RATIO  HOUR  cell  \n",
       "0        0.001761     0     0  \n",
       "1        0.002468     1     0  \n",
       "2        0.003077     2     0  \n",
       "3        0.001721     3     0  \n",
       "4        0.002213     4     0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/cleaned_KPIs.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d75cb9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['cell_id','index'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8caf7790",
   "metadata": {},
   "source": [
    "# 1. Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "beba0e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "IF=IsolationForest(n_estimators=150, \n",
    "                      max_samples ='auto', \n",
    "                      max_features=1,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1c33a46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.51295825, 0.48509757, 0.53648751, 0.50925568, 0.48977436,\n",
       "       0.52157804, 0.50460632, 0.47403398, 0.47869537, 0.4786467 ,\n",
       "       0.46769137, 0.46808774, 0.47676634, 0.48726571, 0.48067503,\n",
       "       0.50214502, 0.47844321, 0.47284323, 0.46897991, 0.46007395])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IF.fit(df)\n",
    "# score_samples = - score  \n",
    "IF_score = -1 * IF.score_samples(df)\n",
    "IF_score[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158f3a5b",
   "metadata": {},
   "source": [
    "# 2. VAE\n",
    "\n",
    "[keras - Variational AutoEncoder 官方代码范例(复杂)](https://keras.io/examples/generative/vae/)\n",
    "\n",
    "[keras - AE/VAE 相对简单的代码构建](https://blog.keras.io/building-autoencoders-in-keras.html)\n",
    "\n",
    "[keras - 中等程度AVE 但是有点乱](https://github.com/keras-team/keras/blob/2c8d1d03599cc03243bce8f07ed9c4a3d5f384f9/examples/variational_autoencoder.py)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[中文VAE理论+代码](https://blog.csdn.net/weixin_37737254/article/details/102920263)\n",
    "\n",
    "[keras - 函数式API](https://keras.io/guides/functional_api/)\n",
    "\n",
    "[keras - Conv1D](https://keras-zh.readthedocs.io/layers/convolutional/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3164441",
   "metadata": {},
   "source": [
    "## 2.1 Build model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d99a10",
   "metadata": {},
   "source": [
    "**(1) Standardize** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "945523ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled = StandardScaler().fit_transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8f45fb",
   "metadata": {},
   "source": [
    "**(2) Build Encoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9d03e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 20)]              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                336       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 68        \n",
      "=================================================================\n",
      "Total params: 404\n",
      "Trainable params: 404\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "original_dim = df.shape[1]\n",
    "intermediate_dim = 16\n",
    "latent_dim = 4\n",
    "\n",
    "# encoder input\n",
    "inputs = keras.Input(shape=(original_dim,))\n",
    "x = layers.Dense(intermediate_dim, activation=\"relu\")(inputs)\n",
    "z = layers.Dense(latent_dim, activation=\"relu\")(x)\n",
    "\n",
    "# Create encoder\n",
    "encoder = keras.Model(inputs, z, name='encoder')\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a86f8c",
   "metadata": {},
   "source": [
    "**(3) Build Decoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12179934",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "z (InputLayer)               [(None, 4)]               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 20)                340       \n",
      "=================================================================\n",
      "Total params: 420\n",
      "Trainable params: 420\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create decoder\n",
    "latent_inputs = keras.Input(shape=(latent_dim,), name='z')\n",
    "x = layers.Dense(intermediate_dim, activation='relu')(latent_inputs)\n",
    "y = layers.Dense(original_dim, activation='relu')(x)\n",
    "decoder = keras.Model(latent_inputs, y, name='decoder')\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adb2e38",
   "metadata": {},
   "source": [
    "**(4) Build AutoEncoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55cd58bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate VAE model\n",
    "outputs = decoder(encoder(inputs))\n",
    "ae = keras.Model(inputs, outputs, name='auto-encoder')\n",
    "\n",
    "# Optimiser \n",
    "adam = keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "# Add loss function\n",
    "ae.compile(optimizer=adam,loss=\"mse\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375b054b",
   "metadata": {},
   "source": [
    "Notices:\n",
    "- weight of kl_loss?  [theoretical insight](https://stats.stackexchange.com/questions/332179/how-to-weight-kld-loss-vs-reconstruction-loss-in-variational-auto-encoder) + [a more specific example](https://stats.stackexchange.com/questions/341954/balancing-reconstruction-vs-kl-loss-variational-autoencoder)\n",
    "- reconsctruction_loss : if use `binary_crossentropy`( $BCE(y,p)=-y.log(p)-(1-y).log(1-p)$ ), the input value should be in 0~1. In our case, since we use 'StandardScaler', we'd better use `mse`, otherwise, when training the model, the loss becomes -inf "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4a3e53",
   "metadata": {},
   "source": [
    "**(5) Train model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96e63ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8279 samples, validate on 8279 samples\n",
      "Epoch 1/500\n",
      "8279/8279 [==============================] - 0s 45us/sample - loss: 0.8233 - val_loss: 0.8030\n",
      "Epoch 2/500\n",
      "8279/8279 [==============================] - 0s 15us/sample - loss: 0.7958 - val_loss: 0.7892\n",
      "Epoch 3/500\n",
      "8279/8279 [==============================] - 0s 16us/sample - loss: 0.7852 - val_loss: 0.7812\n",
      "Epoch 4/500\n",
      "8279/8279 [==============================] - 0s 16us/sample - loss: 0.7783 - val_loss: 0.7751\n",
      "Epoch 5/500\n",
      "8279/8279 [==============================] - 0s 16us/sample - loss: 0.7728 - val_loss: 0.7695\n",
      "Epoch 6/500\n",
      "8279/8279 [==============================] - 0s 15us/sample - loss: 0.7671 - val_loss: 0.7641\n",
      "Epoch 7/500\n",
      "8279/8279 [==============================] - 0s 15us/sample - loss: 0.7628 - val_loss: 0.7609\n",
      "Epoch 8/500\n",
      "8279/8279 [==============================] - 0s 16us/sample - loss: 0.7599 - val_loss: 0.7585\n",
      "Epoch 9/500\n",
      "8279/8279 [==============================] - 0s 16us/sample - loss: 0.7578 - val_loss: 0.7567\n",
      "Epoch 10/500\n",
      "8279/8279 [==============================] - 0s 16us/sample - loss: 0.7561 - val_loss: 0.7552\n",
      "Epoch 11/500\n",
      "8279/8279 [==============================] - 0s 15us/sample - loss: 0.7547 - val_loss: 0.7541\n",
      "Epoch 12/500\n",
      "8279/8279 [==============================] - 0s 15us/sample - loss: 0.7537 - val_loss: 0.7531\n",
      "Epoch 13/500\n",
      "8279/8279 [==============================] - 0s 16us/sample - loss: 0.7529 - val_loss: 0.7523\n",
      "Epoch 14/500\n",
      "8279/8279 [==============================] - 0s 16us/sample - loss: 0.7521 - val_loss: 0.7517\n",
      "Epoch 15/500\n",
      "8279/8279 [==============================] - 0s 16us/sample - loss: 0.7515 - val_loss: 0.7510\n",
      "Epoch 16/500\n",
      "8279/8279 [==============================] - 0s 17us/sample - loss: 0.7509 - val_loss: 0.7506\n",
      "Epoch 17/500\n",
      "8279/8279 [==============================] - 0s 16us/sample - loss: 0.7504 - val_loss: 0.7501\n",
      "Epoch 18/500\n",
      "8279/8279 [==============================] - 0s 15us/sample - loss: 0.7500 - val_loss: 0.7498\n",
      "Epoch 19/500\n",
      "8279/8279 [==============================] - 0s 16us/sample - loss: 0.7497 - val_loss: 0.7493\n",
      "Epoch 20/500\n",
      "8279/8279 [==============================] - 0s 15us/sample - loss: 0.7493 - val_loss: 0.7490\n",
      "Epoch 21/500\n",
      "8279/8279 [==============================] - 0s 17us/sample - loss: 0.7490 - val_loss: 0.7487\n",
      "Epoch 22/500\n",
      "8279/8279 [==============================] - 0s 16us/sample - loss: 0.7486 - val_loss: 0.7483\n",
      "Epoch 23/500\n",
      "8279/8279 [==============================] - 0s 17us/sample - loss: 0.7483 - val_loss: 0.7480\n",
      "Epoch 24/500\n",
      "8279/8279 [==============================] - 0s 15us/sample - loss: 0.7480 - val_loss: 0.7477\n",
      "Epoch 25/500\n",
      "8279/8279 [==============================] - 0s 15us/sample - loss: 0.7477 - val_loss: 0.7474\n",
      "Epoch 26/500\n",
      "8279/8279 [==============================] - 0s 16us/sample - loss: 0.7474 - val_loss: 0.7471\n",
      "Epoch 27/500\n",
      "8279/8279 [==============================] - 0s 17us/sample - loss: 0.7471 - val_loss: 0.7468\n",
      "Epoch 28/500\n",
      "8279/8279 [==============================] - 0s 17us/sample - loss: 0.7468 - val_loss: 0.7466\n",
      "Epoch 29/500\n",
      "8279/8279 [==============================] - 0s 16us/sample - loss: 0.7466 - val_loss: 0.7463\n",
      "Epoch 30/500\n",
      "8279/8279 [==============================] - 0s 16us/sample - loss: 0.7463 - val_loss: 0.7462\n",
      "Epoch 31/500\n",
      "8279/8279 [==============================] - 0s 16us/sample - loss: 0.7461 - val_loss: 0.7458\n",
      "Epoch 32/500\n",
      "8279/8279 [==============================] - 0s 16us/sample - loss: 0.7458 - val_loss: 0.7455\n",
      "Epoch 33/500\n",
      "8279/8279 [==============================] - 0s 15us/sample - loss: 0.7453 - val_loss: 0.7449\n",
      "Epoch 34/500\n",
      "8279/8279 [==============================] - 0s 16us/sample - loss: 0.7446 - val_loss: 0.7441\n",
      "Epoch 35/500\n",
      "8279/8279 [==============================] - 0s 16us/sample - loss: 0.7440 - val_loss: 0.7437\n",
      "Epoch 36/500\n",
      "8279/8279 [==============================] - 0s 17us/sample - loss: 0.7436 - val_loss: 0.7433\n",
      "Epoch 37/500\n",
      "8279/8279 [==============================] - 0s 15us/sample - loss: 0.7433 - val_loss: 0.7431\n",
      "Epoch 38/500\n",
      "8279/8279 [==============================] - 0s 15us/sample - loss: 0.7431 - val_loss: 0.7429\n",
      "Epoch 39/500\n",
      "8279/8279 [==============================] - 0s 15us/sample - loss: 0.7429 - val_loss: 0.7428\n",
      "Epoch 40/500\n",
      "8279/8279 [==============================] - 0s 15us/sample - loss: 0.7427 - val_loss: 0.7424\n",
      "Epoch 41/500\n",
      "8279/8279 [==============================] - 0s 15us/sample - loss: 0.7424 - val_loss: 0.7423\n",
      "Epoch 42/500\n",
      "8279/8279 [==============================] - 0s 15us/sample - loss: 0.7423 - val_loss: 0.7421\n",
      "Epoch 43/500\n",
      "8279/8279 [==============================] - 0s 16us/sample - loss: 0.7420 - val_loss: 0.7419\n",
      "Epoch 44/500\n",
      "8279/8279 [==============================] - 0s 15us/sample - loss: 0.7416 - val_loss: 0.7411\n",
      "Epoch 45/500\n",
      "8279/8279 [==============================] - 0s 16us/sample - loss: 0.7409 - val_loss: 0.7405\n",
      "Epoch 46/500\n",
      "8279/8279 [==============================] - 0s 17us/sample - loss: 0.7403 - val_loss: 0.7399\n",
      "Epoch 47/500\n",
      "8279/8279 [==============================] - 0s 16us/sample - loss: 0.7398 - val_loss: 0.7396\n",
      "Epoch 48/500\n",
      "8279/8279 [==============================] - 0s 16us/sample - loss: 0.7395 - val_loss: 0.7393\n",
      "Epoch 49/500\n",
      "8279/8279 [==============================] - 0s 17us/sample - loss: 0.7392 - val_loss: 0.7390\n",
      "Epoch 50/500\n",
      "8279/8279 [==============================] - 0s 15us/sample - loss: 0.7391 - val_loss: 0.7389\n",
      "Epoch 51/500\n",
      "8279/8279 [==============================] - 0s 16us/sample - loss: 0.7390 - val_loss: 0.7388\n",
      "Epoch 52/500\n",
      "8279/8279 [==============================] - 0s 21us/sample - loss: 0.7388 - val_loss: 0.7386\n",
      "Epoch 53/500\n",
      "8279/8279 [==============================] - 0s 16us/sample - loss: 0.7387 - val_loss: 0.7385\n",
      "Epoch 54/500\n",
      "8279/8279 [==============================] - 0s 15us/sample - loss: 0.7385 - val_loss: 0.7384\n",
      "Epoch 55/500\n",
      "8279/8279 [==============================] - 0s 17us/sample - loss: 0.7385 - val_loss: 0.7383\n",
      "Epoch 56/500\n",
      "8279/8279 [==============================] - 0s 17us/sample - loss: 0.7384 - val_loss: 0.7383\n",
      "Epoch 57/500\n",
      "8279/8279 [==============================] - 0s 16us/sample - loss: 0.7383 - val_loss: 0.7382\n",
      "Epoch 58/500\n",
      "8279/8279 [==============================] - 0s 16us/sample - loss: 0.7382 - val_loss: 0.7381\n",
      "Epoch 59/500\n",
      "8279/8279 [==============================] - 0s 16us/sample - loss: 0.7381 - val_loss: 0.7381\n",
      "Epoch 60/500\n",
      "8279/8279 [==============================] - 0s 15us/sample - loss: 0.7381 - val_loss: 0.7380\n",
      "Epoch 61/500\n",
      "8279/8279 [==============================] - 0s 15us/sample - loss: 0.7380 - val_loss: 0.7379\n",
      "Epoch 62/500\n",
      "8279/8279 [==============================] - 0s 17us/sample - loss: 0.7380 - val_loss: 0.7379\n",
      "Epoch 63/500\n",
      "8279/8279 [==============================] - 0s 16us/sample - loss: 0.7379 - val_loss: 0.7377\n",
      "Epoch 64/500\n",
      "8279/8279 [==============================] - 0s 15us/sample - loss: 0.7378 - val_loss: 0.7377\n",
      "Epoch 65/500\n",
      "8279/8279 [==============================] - 0s 16us/sample - loss: 0.7378 - val_loss: 0.7378\n",
      "Epoch 66/500\n",
      "8279/8279 [==============================] - 0s 17us/sample - loss: 0.7378 - val_loss: 0.7377\n",
      "Epoch 67/500\n",
      "8279/8279 [==============================] - 0s 16us/sample - loss: 0.7377 - val_loss: 0.7376\n",
      "Epoch 68/500\n",
      "8279/8279 [==============================] - 0s 15us/sample - loss: 0.7376 - val_loss: 0.7375\n",
      "Epoch 69/500\n",
      "8279/8279 [==============================] - 0s 15us/sample - loss: 0.7375 - val_loss: 0.7374\n",
      "Epoch 70/500\n",
      "8279/8279 [==============================] - 0s 15us/sample - loss: 0.7375 - val_loss: 0.7374\n",
      "Epoch 71/500\n",
      "8279/8279 [==============================] - 0s 15us/sample - loss: 0.7374 - val_loss: 0.7373\n",
      "Epoch 72/500\n",
      "8279/8279 [==============================] - 0s 15us/sample - loss: 0.7374 - val_loss: 0.7373\n",
      "Epoch 73/500\n",
      "8279/8279 [==============================] - 0s 16us/sample - loss: 0.7373 - val_loss: 0.7373\n",
      "Epoch 74/500\n",
      "8279/8279 [==============================] - 0s 16us/sample - loss: 0.7373 - val_loss: 0.7372\n",
      "Epoch 75/500\n",
      "8279/8279 [==============================] - 0s 15us/sample - loss: 0.7372 - val_loss: 0.7371\n",
      "Epoch 76/500\n",
      "8279/8279 [==============================] - 0s 15us/sample - loss: 0.7371 - val_loss: 0.7370\n",
      "Epoch 77/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8279/8279 [==============================] - 0s 16us/sample - loss: 0.7371 - val_loss: 0.7370\n",
      "Epoch 78/500\n",
      "8279/8279 [==============================] - 0s 15us/sample - loss: 0.7370 - val_loss: 0.7369\n",
      "Epoch 79/500\n",
      "8279/8279 [==============================] - 0s 15us/sample - loss: 0.7370 - val_loss: 0.7369\n",
      "Epoch 80/500\n",
      "8279/8279 [==============================] - 0s 15us/sample - loss: 0.7369 - val_loss: 0.7368\n",
      "Epoch 81/500\n",
      "8279/8279 [==============================] - 0s 16us/sample - loss: 0.7369 - val_loss: 0.7369\n",
      "Epoch 82/500\n",
      "8279/8279 [==============================] - 0s 17us/sample - loss: 0.7368 - val_loss: 0.7368\n",
      "Epoch 83/500\n",
      "8279/8279 [==============================] - 0s 15us/sample - loss: 0.7368 - val_loss: 0.7367\n",
      "Epoch 84/500\n",
      "8279/8279 [==============================] - 0s 15us/sample - loss: 0.7367 - val_loss: 0.7366\n",
      "Epoch 85/500\n",
      "8279/8279 [==============================] - 0s 16us/sample - loss: 0.7367 - val_loss: 0.7366\n",
      "Epoch 86/500\n",
      "8279/8279 [==============================] - 0s 16us/sample - loss: 0.7366 - val_loss: 0.7366\n",
      "Epoch 87/500\n",
      "8279/8279 [==============================] - 0s 17us/sample - loss: 0.7366 - val_loss: 0.7365\n",
      "Epoch 88/500\n",
      "8279/8279 [==============================] - 0s 16us/sample - loss: 0.7366 - val_loss: 0.7365\n",
      "Epoch 89/500\n",
      "8279/8279 [==============================] - 0s 15us/sample - loss: 0.7365 - val_loss: 0.7365\n",
      "Epoch 90/500\n",
      "8279/8279 [==============================] - 0s 15us/sample - loss: 0.7365 - val_loss: 0.7364\n",
      "Epoch 91/500\n",
      "8279/8279 [==============================] - 0s 15us/sample - loss: 0.7364 - val_loss: 0.7363\n",
      "Epoch 92/500\n",
      "8279/8279 [==============================] - 0s 17us/sample - loss: 0.7364 - val_loss: 0.7364\n",
      "Epoch 93/500\n",
      "8279/8279 [==============================] - 0s 16us/sample - loss: 0.7364 - val_loss: 0.7363\n",
      "Epoch 94/500\n",
      "8279/8279 [==============================] - 0s 15us/sample - loss: 0.7364 - val_loss: 0.7364\n",
      "Epoch 95/500\n",
      "8279/8279 [==============================] - 0s 15us/sample - loss: 0.7363 - val_loss: 0.7362\n",
      "Epoch 96/500\n",
      "8279/8279 [==============================] - 0s 15us/sample - loss: 0.7362 - val_loss: 0.7362\n",
      "Epoch 97/500\n",
      "8279/8279 [==============================] - 0s 15us/sample - loss: 0.7362 - val_loss: 0.7361\n",
      "Epoch 98/500\n",
      "8279/8279 [==============================] - 0s 15us/sample - loss: 0.7362 - val_loss: 0.7361\n",
      "Epoch 99/500\n",
      "8279/8279 [==============================] - 0s 15us/sample - loss: 0.7361 - val_loss: 0.7361\n",
      "Epoch 100/500\n",
      "8279/8279 [==============================] - 0s 15us/sample - loss: 0.7361 - val_loss: 0.7360\n",
      "Epoch 101/500\n",
      "8279/8279 [==============================] - 0s 15us/sample - loss: 0.7361 - val_loss: 0.7360\n",
      "Epoch 102/500\n",
      "8279/8279 [==============================] - 0s 15us/sample - loss: 0.7361 - val_loss: 0.7360\n",
      "Epoch 103/500\n",
      "8279/8279 [==============================] - 0s 19us/sample - loss: 0.7360 - val_loss: 0.7359\n",
      "Epoch 104/500\n",
      "8279/8279 [==============================] - 0s 15us/sample - loss: 0.7360 - val_loss: 0.7359\n",
      "Epoch 105/500\n",
      "8279/8279 [==============================] - 0s 15us/sample - loss: 0.7359 - val_loss: 0.7359\n",
      "Epoch 106/500\n",
      "8279/8279 [==============================] - 0s 15us/sample - loss: 0.7359 - val_loss: 0.7358\n",
      "Epoch 107/500\n",
      "8279/8279 [==============================] - 0s 15us/sample - loss: 0.7359 - val_loss: 0.7358\n",
      "Epoch 108/500\n",
      "8279/8279 [==============================] - 0s 16us/sample - loss: 0.7358 - val_loss: 0.7358\n",
      "Epoch 109/500\n",
      "8279/8279 [==============================] - 0s 16us/sample - loss: 0.7358 - val_loss: 0.7358\n",
      "Epoch 110/500\n",
      "8279/8279 [==============================] - 0s 17us/sample - loss: 0.7358 - val_loss: 0.7357\n",
      "Epoch 111/500\n",
      "8279/8279 [==============================] - 0s 16us/sample - loss: 0.7357 - val_loss: 0.7357\n",
      "Epoch 112/500\n",
      "8279/8279 [==============================] - 0s 15us/sample - loss: 0.7357 - val_loss: 0.7356\n",
      "Epoch 113/500\n",
      "8279/8279 [==============================] - 0s 15us/sample - loss: 0.7357 - val_loss: 0.7357\n",
      "Epoch 114/500\n",
      "8279/8279 [==============================] - 0s 15us/sample - loss: 0.7357 - val_loss: 0.7357\n",
      "Epoch 115/500\n",
      "8279/8279 [==============================] - 0s 16us/sample - loss: 0.7356 - val_loss: 0.7356\n",
      "Epoch 116/500\n",
      "8279/8279 [==============================] - 0s 16us/sample - loss: 0.7356 - val_loss: 0.7356\n",
      "Epoch 117/500\n",
      "8279/8279 [==============================] - 0s 15us/sample - loss: 0.7356 - val_loss: 0.7355\n",
      "Epoch 118/500\n",
      "8279/8279 [==============================] - 0s 16us/sample - loss: 0.7356 - val_loss: 0.7355\n",
      "Epoch 119/500\n",
      "8279/8279 [==============================] - 0s 16us/sample - loss: 0.7355 - val_loss: 0.7355\n",
      "Epoch 120/500\n",
      "8279/8279 [==============================] - 0s 17us/sample - loss: 0.7356 - val_loss: 0.7355\n",
      "Epoch 121/500\n",
      "8279/8279 [==============================] - 0s 17us/sample - loss: 0.7355 - val_loss: 0.7354\n",
      "Epoch 122/500\n",
      "8279/8279 [==============================] - 0s 17us/sample - loss: 0.7355 - val_loss: 0.7355\n",
      "Epoch 123/500\n",
      "8279/8279 [==============================] - 0s 16us/sample - loss: 0.7354 - val_loss: 0.7354\n",
      "Epoch 124/500\n",
      "8279/8279 [==============================] - 0s 16us/sample - loss: 0.7354 - val_loss: 0.7354\n",
      "Epoch 125/500\n",
      "8279/8279 [==============================] - 0s 17us/sample - loss: 0.7354 - val_loss: 0.7353\n",
      "Epoch 126/500\n",
      "8279/8279 [==============================] - 0s 16us/sample - loss: 0.7354 - val_loss: 0.7353\n",
      "Epoch 127/500\n",
      "8279/8279 [==============================] - 0s 16us/sample - loss: 0.7354 - val_loss: 0.7353\n",
      "Epoch 128/500\n",
      "8279/8279 [==============================] - 0s 16us/sample - loss: 0.7353 - val_loss: 0.7353\n",
      "Epoch 129/500\n",
      "8279/8279 [==============================] - 0s 16us/sample - loss: 0.7353 - val_loss: 0.7352\n",
      "Epoch 130/500\n",
      "8279/8279 [==============================] - 0s 16us/sample - loss: 0.7353 - val_loss: 0.7352\n",
      "Epoch 131/500\n",
      "8279/8279 [==============================] - 0s 16us/sample - loss: 0.7353 - val_loss: 0.7352\n",
      "Epoch 132/500\n",
      "8279/8279 [==============================] - 0s 16us/sample - loss: 0.7353 - val_loss: 0.7352\n",
      "Epoch 133/500\n",
      "8279/8279 [==============================] - 0s 15us/sample - loss: 0.7353 - val_loss: 0.7352\n",
      "Epoch 134/500\n",
      "8279/8279 [==============================] - 0s 15us/sample - loss: 0.7352 - val_loss: 0.7351\n",
      "Epoch 135/500\n",
      "8279/8279 [==============================] - 0s 16us/sample - loss: 0.7352 - val_loss: 0.7352\n",
      "Epoch 136/500\n",
      "8279/8279 [==============================] - 0s 16us/sample - loss: 0.7352 - val_loss: 0.7352\n",
      "Epoch 137/500\n",
      "8279/8279 [==============================] - 0s 16us/sample - loss: 0.7352 - val_loss: 0.7351\n",
      "Epoch 138/500\n",
      "8279/8279 [==============================] - 0s 16us/sample - loss: 0.7352 - val_loss: 0.7351\n",
      "Epoch 139/500\n",
      "8279/8279 [==============================] - 0s 15us/sample - loss: 0.7352 - val_loss: 0.7351\n",
      "Epoch 140/500\n",
      "8279/8279 [==============================] - 0s 15us/sample - loss: 0.7351 - val_loss: 0.7350\n",
      "Epoch 141/500\n",
      "8279/8279 [==============================] - 0s 16us/sample - loss: 0.7351 - val_loss: 0.7351\n",
      "Epoch 142/500\n",
      "8279/8279 [==============================] - 0s 15us/sample - loss: 0.7351 - val_loss: 0.7350\n",
      "Epoch 143/500\n",
      "8279/8279 [==============================] - 0s 16us/sample - loss: 0.7351 - val_loss: 0.7350\n",
      "Epoch 144/500\n",
      "8279/8279 [==============================] - 0s 18us/sample - loss: 0.7351 - val_loss: 0.7350\n",
      "Epoch 145/500\n",
      "8279/8279 [==============================] - 0s 17us/sample - loss: 0.7351 - val_loss: 0.7350\n",
      "Epoch 146/500\n",
      "8279/8279 [==============================] - 0s 16us/sample - loss: 0.7350 - val_loss: 0.7350\n",
      "Epoch 147/500\n",
      "8279/8279 [==============================] - 0s 15us/sample - loss: 0.7350 - val_loss: 0.7350\n",
      "Epoch 148/500\n",
      "8279/8279 [==============================] - 0s 15us/sample - loss: 0.7350 - val_loss: 0.7350\n",
      "Epoch 149/500\n",
      "8279/8279 [==============================] - 0s 15us/sample - loss: 0.7350 - val_loss: 0.7349\n",
      "Epoch 150/500\n",
      "8279/8279 [==============================] - 0s 15us/sample - loss: 0.7350 - val_loss: 0.7349\n",
      "Epoch 151/500\n",
      "8279/8279 [==============================] - 0s 16us/sample - loss: 0.7350 - val_loss: 0.7349\n",
      "Epoch 152/500\n",
      "8279/8279 [==============================] - 0s 15us/sample - loss: 0.7350 - val_loss: 0.7349\n",
      "Epoch 153/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8279/8279 [==============================] - 0s 15us/sample - loss: 0.7350 - val_loss: 0.7349\n",
      "Epoch 154/500\n",
      "8279/8279 [==============================] - 0s 16us/sample - loss: 0.7349 - val_loss: 0.7348\n",
      "Epoch 155/500\n",
      "8279/8279 [==============================] - 0s 20us/sample - loss: 0.7349 - val_loss: 0.7348\n",
      "Epoch 156/500\n",
      "8279/8279 [==============================] - 0s 19us/sample - loss: 0.7349 - val_loss: 0.7348\n",
      "Epoch 157/500\n",
      "8279/8279 [==============================] - 0s 16us/sample - loss: 0.7349 - val_loss: 0.7348\n",
      "Epoch 158/500\n",
      "8279/8279 [==============================] - 0s 16us/sample - loss: 0.7349 - val_loss: 0.7348\n",
      "Epoch 159/500\n",
      "8279/8279 [==============================] - 0s 17us/sample - loss: 0.7349 - val_loss: 0.7348\n",
      "Epoch 160/500\n",
      "8279/8279 [==============================] - 0s 17us/sample - loss: 0.7348 - val_loss: 0.7348\n",
      "Epoch 161/500\n",
      "8279/8279 [==============================] - 0s 18us/sample - loss: 0.7348 - val_loss: 0.7349\n",
      "Epoch 162/500\n",
      "8279/8279 [==============================] - 0s 18us/sample - loss: 0.7348 - val_loss: 0.7347\n",
      "Epoch 163/500\n",
      "8279/8279 [==============================] - 0s 18us/sample - loss: 0.7348 - val_loss: 0.7348\n",
      "Epoch 164/500\n",
      "8279/8279 [==============================] - 0s 18us/sample - loss: 0.7348 - val_loss: 0.7347\n",
      "Epoch 165/500\n",
      "8279/8279 [==============================] - 0s 18us/sample - loss: 0.7348 - val_loss: 0.7347\n",
      "Epoch 166/500\n",
      "8279/8279 [==============================] - 0s 19us/sample - loss: 0.7348 - val_loss: 0.7347\n",
      "Epoch 167/500\n",
      "8279/8279 [==============================] - 0s 29us/sample - loss: 0.7348 - val_loss: 0.7347\n",
      "Epoch 168/500\n",
      "8279/8279 [==============================] - 0s 19us/sample - loss: 0.7347 - val_loss: 0.7347\n",
      "Epoch 169/500\n",
      "8279/8279 [==============================] - 0s 21us/sample - loss: 0.7348 - val_loss: 0.7347\n",
      "Epoch 170/500\n",
      "8279/8279 [==============================] - 0s 20us/sample - loss: 0.7347 - val_loss: 0.7347\n",
      "Epoch 171/500\n",
      "8279/8279 [==============================] - 0s 20us/sample - loss: 0.7347 - val_loss: 0.7347\n",
      "Epoch 172/500\n",
      "8279/8279 [==============================] - 0s 20us/sample - loss: 0.7347 - val_loss: 0.7346\n",
      "Epoch 173/500\n",
      "8279/8279 [==============================] - 0s 19us/sample - loss: 0.7347 - val_loss: 0.7346\n",
      "Epoch 174/500\n",
      "8279/8279 [==============================] - 0s 19us/sample - loss: 0.7347 - val_loss: 0.7347\n",
      "Epoch 175/500\n",
      "8279/8279 [==============================] - 0s 22us/sample - loss: 0.7347 - val_loss: 0.7346\n",
      "Epoch 176/500\n",
      "8279/8279 [==============================] - 0s 20us/sample - loss: 0.7347 - val_loss: 0.7347\n",
      "Epoch 177/500\n",
      "8279/8279 [==============================] - 0s 21us/sample - loss: 0.7347 - val_loss: 0.7347\n",
      "Epoch 178/500\n",
      "8279/8279 [==============================] - 0s 19us/sample - loss: 0.7347 - val_loss: 0.7346\n",
      "Epoch 179/500\n",
      "8279/8279 [==============================] - 0s 20us/sample - loss: 0.7346 - val_loss: 0.7346\n",
      "Epoch 180/500\n",
      "8279/8279 [==============================] - 0s 18us/sample - loss: 0.7346 - val_loss: 0.7345\n",
      "Epoch 181/500\n",
      "8279/8279 [==============================] - 0s 19us/sample - loss: 0.7346 - val_loss: 0.7346\n",
      "Epoch 182/500\n",
      "8279/8279 [==============================] - 0s 19us/sample - loss: 0.7346 - val_loss: 0.7345\n",
      "Epoch 183/500\n",
      "8279/8279 [==============================] - 0s 21us/sample - loss: 0.7346 - val_loss: 0.7346\n",
      "Epoch 184/500\n",
      "8279/8279 [==============================] - 0s 19us/sample - loss: 0.7346 - val_loss: 0.7346\n",
      "Epoch 185/500\n",
      "8279/8279 [==============================] - 0s 18us/sample - loss: 0.7346 - val_loss: 0.7345\n",
      "Epoch 186/500\n",
      "8279/8279 [==============================] - 0s 19us/sample - loss: 0.7345 - val_loss: 0.7345\n",
      "Epoch 187/500\n",
      "8279/8279 [==============================] - 0s 19us/sample - loss: 0.7345 - val_loss: 0.7345\n",
      "Epoch 188/500\n",
      "8279/8279 [==============================] - 0s 21us/sample - loss: 0.7345 - val_loss: 0.7345\n",
      "Epoch 189/500\n",
      "8279/8279 [==============================] - 0s 20us/sample - loss: 0.7346 - val_loss: 0.7345\n",
      "Epoch 190/500\n",
      "8279/8279 [==============================] - 0s 21us/sample - loss: 0.7345 - val_loss: 0.7344\n",
      "Epoch 191/500\n",
      "8279/8279 [==============================] - 0s 20us/sample - loss: 0.7345 - val_loss: 0.7345\n",
      "Epoch 192/500\n",
      "8279/8279 [==============================] - 0s 31us/sample - loss: 0.7345 - val_loss: 0.7344\n",
      "Epoch 193/500\n",
      "8279/8279 [==============================] - 0s 23us/sample - loss: 0.7346 - val_loss: 0.7345\n",
      "Epoch 194/500\n",
      "8279/8279 [==============================] - 0s 26us/sample - loss: 0.7345 - val_loss: 0.7344\n",
      "Epoch 195/500\n",
      "8279/8279 [==============================] - 0s 21us/sample - loss: 0.7345 - val_loss: 0.7344\n",
      "Epoch 196/500\n",
      "8279/8279 [==============================] - 0s 22us/sample - loss: 0.7345 - val_loss: 0.7344\n",
      "Epoch 197/500\n",
      "8279/8279 [==============================] - 0s 25us/sample - loss: 0.7345 - val_loss: 0.7344\n",
      "Epoch 198/500\n",
      "8279/8279 [==============================] - 0s 20us/sample - loss: 0.7345 - val_loss: 0.7344\n",
      "Epoch 199/500\n",
      "8279/8279 [==============================] - 0s 21us/sample - loss: 0.7345 - val_loss: 0.7343\n",
      "Epoch 200/500\n",
      "8279/8279 [==============================] - 0s 20us/sample - loss: 0.7344 - val_loss: 0.7344\n",
      "Epoch 201/500\n",
      "8279/8279 [==============================] - 0s 19us/sample - loss: 0.7344 - val_loss: 0.7345\n",
      "Epoch 202/500\n",
      "8279/8279 [==============================] - 0s 23us/sample - loss: 0.7344 - val_loss: 0.7344\n",
      "Epoch 203/500\n",
      "8279/8279 [==============================] - 0s 20us/sample - loss: 0.7344 - val_loss: 0.7344\n",
      "Epoch 204/500\n",
      "8279/8279 [==============================] - 0s 18us/sample - loss: 0.7344 - val_loss: 0.7344\n",
      "Epoch 205/500\n",
      "8279/8279 [==============================] - 0s 23us/sample - loss: 0.7344 - val_loss: 0.7344\n",
      "Epoch 206/500\n",
      "8279/8279 [==============================] - 0s 21us/sample - loss: 0.7344 - val_loss: 0.7343\n",
      "Epoch 207/500\n",
      "8279/8279 [==============================] - 0s 19us/sample - loss: 0.7343 - val_loss: 0.7344\n",
      "Epoch 208/500\n",
      "8279/8279 [==============================] - 0s 19us/sample - loss: 0.7344 - val_loss: 0.7343\n",
      "Epoch 209/500\n",
      "8279/8279 [==============================] - 0s 21us/sample - loss: 0.7343 - val_loss: 0.7344\n",
      "Epoch 210/500\n",
      "8279/8279 [==============================] - 0s 18us/sample - loss: 0.7344 - val_loss: 0.7343\n",
      "Epoch 211/500\n",
      "8279/8279 [==============================] - 0s 19us/sample - loss: 0.7344 - val_loss: 0.7343\n",
      "Epoch 212/500\n",
      "8279/8279 [==============================] - 0s 22us/sample - loss: 0.7343 - val_loss: 0.7343\n",
      "Epoch 213/500\n",
      "8279/8279 [==============================] - 0s 18us/sample - loss: 0.7343 - val_loss: 0.7343\n",
      "Epoch 214/500\n",
      "8279/8279 [==============================] - 0s 21us/sample - loss: 0.7343 - val_loss: 0.7342\n",
      "Epoch 215/500\n",
      "8279/8279 [==============================] - 0s 20us/sample - loss: 0.7343 - val_loss: 0.7343\n",
      "Epoch 216/500\n",
      "8279/8279 [==============================] - 0s 20us/sample - loss: 0.7343 - val_loss: 0.7342\n",
      "Epoch 217/500\n",
      "8279/8279 [==============================] - 0s 22us/sample - loss: 0.7343 - val_loss: 0.7342\n",
      "Epoch 218/500\n",
      "8279/8279 [==============================] - 0s 20us/sample - loss: 0.7343 - val_loss: 0.7342\n",
      "Epoch 219/500\n",
      "8279/8279 [==============================] - 0s 27us/sample - loss: 0.7343 - val_loss: 0.7343\n",
      "Epoch 220/500\n",
      "8279/8279 [==============================] - 0s 20us/sample - loss: 0.7343 - val_loss: 0.7343\n",
      "Epoch 221/500\n",
      "8279/8279 [==============================] - 0s 22us/sample - loss: 0.7342 - val_loss: 0.7342\n",
      "Epoch 222/500\n",
      "8279/8279 [==============================] - 0s 19us/sample - loss: 0.7343 - val_loss: 0.7342\n",
      "Epoch 223/500\n",
      "8279/8279 [==============================] - 0s 19us/sample - loss: 0.7343 - val_loss: 0.7343\n",
      "Epoch 224/500\n",
      "8279/8279 [==============================] - 0s 18us/sample - loss: 0.7343 - val_loss: 0.7343\n",
      "Epoch 225/500\n",
      "8279/8279 [==============================] - 0s 18us/sample - loss: 0.7342 - val_loss: 0.7342\n",
      "Epoch 226/500\n",
      "8279/8279 [==============================] - 0s 21us/sample - loss: 0.7343 - val_loss: 0.7342\n",
      "Epoch 227/500\n",
      "8279/8279 [==============================] - 0s 21us/sample - loss: 0.7343 - val_loss: 0.7343\n",
      "Epoch 228/500\n",
      "8279/8279 [==============================] - 0s 25us/sample - loss: 0.7342 - val_loss: 0.7341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/500\n",
      "8279/8279 [==============================] - 0s 19us/sample - loss: 0.7342 - val_loss: 0.7342\n",
      "Epoch 230/500\n",
      "8279/8279 [==============================] - 0s 18us/sample - loss: 0.7342 - val_loss: 0.7341\n",
      "Epoch 231/500\n",
      "8279/8279 [==============================] - 0s 19us/sample - loss: 0.7342 - val_loss: 0.7342\n",
      "Epoch 232/500\n",
      "8279/8279 [==============================] - 0s 19us/sample - loss: 0.7342 - val_loss: 0.7342\n",
      "Epoch 233/500\n",
      "8279/8279 [==============================] - 0s 19us/sample - loss: 0.7342 - val_loss: 0.7342\n",
      "Epoch 234/500\n",
      "8279/8279 [==============================] - 0s 19us/sample - loss: 0.7342 - val_loss: 0.7342\n",
      "Epoch 235/500\n",
      "8279/8279 [==============================] - 0s 23us/sample - loss: 0.7342 - val_loss: 0.7341\n",
      "Epoch 236/500\n",
      "8279/8279 [==============================] - 0s 24us/sample - loss: 0.7342 - val_loss: 0.7341\n",
      "Epoch 237/500\n",
      "8279/8279 [==============================] - 0s 26us/sample - loss: 0.7342 - val_loss: 0.7341\n",
      "Epoch 238/500\n",
      "8279/8279 [==============================] - 0s 24us/sample - loss: 0.7341 - val_loss: 0.7341\n",
      "Epoch 239/500\n",
      "8279/8279 [==============================] - 0s 25us/sample - loss: 0.7342 - val_loss: 0.7341\n",
      "Epoch 240/500\n",
      "8279/8279 [==============================] - 0s 27us/sample - loss: 0.7342 - val_loss: 0.7341\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x156cc9700c8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 500\n",
    "batch_size = 128\n",
    "callback = EarlyStopping(monitor='val_loss',patience=10)\n",
    "\n",
    "# Train model\n",
    "ae.fit(df_scaled, df_scaled,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(df_scaled, df_scaled),\n",
    "        shuffle=True,\n",
    "#         verbose=False,\n",
    "        callbacks=[callback]\n",
    "       )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ade81d5",
   "metadata": {},
   "source": [
    "## 2.2 [Detect Anomaly](https://towardsdatascience.com/hands-on-anomaly-detection-with-variational-autoencoders-d4044672acd5)\n",
    "Detect anomaly by finding those who have a high reconstruction loss.\n",
    "\n",
    "\n",
    "Steps:\n",
    "1. Measure error between the original train (clean/normal) set and the output of the model, and generate an error vector representing the error term of each sample.\n",
    "\n",
    "2. Find a relatively extreme value on that vector to use as your error threshold.\n",
    "\n",
    "3. Run the model over the test or real data, in which anomalies are probably mixed with normal data.\n",
    "\n",
    "4. Measure the reconstruction error and mark samples that exhibit an error term higher than the error threshold as anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c710e729",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(original,reconstructed):\n",
    "    return np.mean((original-reconstructed)**2,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aaf1a17a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.93303628, 0.63390621, 1.18056078, 0.396229  , 0.35391262,\n",
       "       1.20375977, 5.06754622, 1.02759443, 1.45984249, 2.16254389,\n",
       "       0.91075599, 0.37151143, 0.6010824 , 1.40124381, 0.94254187,\n",
       "       1.07563632, 1.13370866, 0.45573532, 0.70301635, 0.77639674])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "pred  = ae.predict(df_scaled)\n",
    "\n",
    "AE_loss = mse(df_scaled,pred)\n",
    "AE_loss[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2806fe",
   "metadata": {},
   "source": [
    "# 3. AE + IF (stacking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2cad9f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.784741</td>\n",
       "      <td>0.206964</td>\n",
       "      <td>1.077084</td>\n",
       "      <td>3.274514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.100837</td>\n",
       "      <td>0.569643</td>\n",
       "      <td>0.070241</td>\n",
       "      <td>4.819953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.234570</td>\n",
       "      <td>0.199034</td>\n",
       "      <td>0.448586</td>\n",
       "      <td>6.097384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.354728</td>\n",
       "      <td>0.279683</td>\n",
       "      <td>0.316227</td>\n",
       "      <td>3.145494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.812106</td>\n",
       "      <td>0.626090</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.275085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8274</th>\n",
       "      <td>6.689503</td>\n",
       "      <td>1.460762</td>\n",
       "      <td>3.779755</td>\n",
       "      <td>0.483200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8275</th>\n",
       "      <td>7.058461</td>\n",
       "      <td>1.285158</td>\n",
       "      <td>3.801746</td>\n",
       "      <td>0.982202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8276</th>\n",
       "      <td>4.837620</td>\n",
       "      <td>3.414821</td>\n",
       "      <td>4.729827</td>\n",
       "      <td>2.103478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8277</th>\n",
       "      <td>5.475404</td>\n",
       "      <td>1.003208</td>\n",
       "      <td>2.551054</td>\n",
       "      <td>0.299206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8278</th>\n",
       "      <td>5.557426</td>\n",
       "      <td>1.697351</td>\n",
       "      <td>1.390206</td>\n",
       "      <td>1.403342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8279 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3\n",
       "0     2.784741  0.206964  1.077084  3.274514\n",
       "1     3.100837  0.569643  0.070241  4.819953\n",
       "2     4.234570  0.199034  0.448586  6.097384\n",
       "3     2.354728  0.279683  0.316227  3.145494\n",
       "4     2.812106  0.626090  0.000000  4.275085\n",
       "...        ...       ...       ...       ...\n",
       "8274  6.689503  1.460762  3.779755  0.483200\n",
       "8275  7.058461  1.285158  3.801746  0.982202\n",
       "8276  4.837620  3.414821  4.729827  2.103478\n",
       "8277  5.475404  1.003208  2.551054  0.299206\n",
       "8278  5.557426  1.697351  1.390206  1.403342\n",
       "\n",
       "[8279 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_output = encoder.predict(df_scaled)\n",
    "df_encoded = pd.DataFrame(encoder_output)\n",
    "df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac94f4f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IsolationForest(max_features=1, n_estimators=150, random_state=42)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AE_IF=IsolationForest(n_estimators=150, \n",
    "                       max_samples ='auto', \n",
    "                       max_features=1,random_state=42)\n",
    "AE_IF.fit(df_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "647dd300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.53758229, 0.54292233, 0.56003275, 0.51416726, 0.53251386,\n",
       "       0.54095954, 0.5184242 , 0.49401429, 0.53345771, 0.49237882,\n",
       "       0.48762808, 0.51501159, 0.5295732 , 0.50430891, 0.50259002,\n",
       "       0.51355859, 0.53719554, 0.51235446, 0.54929128, 0.50592772])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AE_IF_score = -1 * AE_IF.score_samples(df_encoded)\n",
    "AE_IF_score[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a4979f",
   "metadata": {},
   "source": [
    "# 4. Combination of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a666419c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    8279.000000\n",
       "mean        0.451213\n",
       "std         0.030114\n",
       "min         0.403969\n",
       "25%         0.428277\n",
       "50%         0.443766\n",
       "75%         0.471093\n",
       "max         0.599004\n",
       "Name: IF_score, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['IF_score'] = IF_score\n",
    "df['IF_score'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "15f0b013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    8279.000000\n",
       "mean        0.734103\n",
       "std         2.080939\n",
       "min         0.027187\n",
       "25%         0.211260\n",
       "50%         0.376910\n",
       "75%         0.767105\n",
       "max        97.651455\n",
       "Name: AE_loss, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['AE_loss'] = AE_loss\n",
    "df['AE_loss'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873cac85",
   "metadata": {},
   "source": [
    "Notice there is some extreme value in `VAE_loss`, which may affect our later visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "426fe229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.788723220525283"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['AE_loss'].quantile(0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c4dd3e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    8279.000000\n",
       "mean        0.484142\n",
       "std         0.034707\n",
       "min         0.423684\n",
       "25%         0.454220\n",
       "50%         0.483750\n",
       "75%         0.507313\n",
       "max         0.705713\n",
       "Name: STACKING_score, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['STACKING_score'] = AE_IF_score\n",
    "df['STACKING_score'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "77f67feb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DL_TRAFFIC_VOLUME</th>\n",
       "      <th>UL_TRAFFIC_VOLUME</th>\n",
       "      <th>Inter_X2_based_HO_prep</th>\n",
       "      <th>VoLTE_total_traffic</th>\n",
       "      <th>INTRA_FREQ_HO_SR_RATIO</th>\n",
       "      <th>RRC_SR_RATIO</th>\n",
       "      <th>CELL_AVAILABILITY_RATIO</th>\n",
       "      <th>RACH_Stp_Completion_SR_RATIO</th>\n",
       "      <th>Inter_RAT_HO_SR_UTRAN_SRVCC_RATIO</th>\n",
       "      <th>E_RAB_QCI1_DR_RATIO</th>\n",
       "      <th>...</th>\n",
       "      <th>E_UTRAN_Inter_Freq_HO_SR_RATIO</th>\n",
       "      <th>Inter_RAT_HO_SR_GERAN_SRVCC_RATIO</th>\n",
       "      <th>Inter_RAT_Total_HO_SR_RATIO</th>\n",
       "      <th>E_UTRAN_tot_HO_SR_inter_eNB_X2_RATIO</th>\n",
       "      <th>E_RAB_DR_RATIO</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>cell</th>\n",
       "      <th>IF_score</th>\n",
       "      <th>AE_loss</th>\n",
       "      <th>STACKING_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.779737e+10</td>\n",
       "      <td>3.947172e+09</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4727.0</td>\n",
       "      <td>0.809859</td>\n",
       "      <td>0.992427</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.962688</td>\n",
       "      <td>0.576414</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.770642</td>\n",
       "      <td>0.963636</td>\n",
       "      <td>0.963636</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.001761</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.512958</td>\n",
       "      <td>0.933036</td>\n",
       "      <td>0.537582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.684898e+10</td>\n",
       "      <td>4.088752e+09</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3076.0</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.993288</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.973207</td>\n",
       "      <td>0.576414</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.002468</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.485098</td>\n",
       "      <td>0.633906</td>\n",
       "      <td>0.542922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.292677e+10</td>\n",
       "      <td>5.016897e+09</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3501.0</td>\n",
       "      <td>0.938356</td>\n",
       "      <td>0.994664</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.966330</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.931624</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.003077</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.536488</td>\n",
       "      <td>1.180561</td>\n",
       "      <td>0.560033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.021547e+10</td>\n",
       "      <td>5.139107e+09</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2275.0</td>\n",
       "      <td>0.860215</td>\n",
       "      <td>0.994819</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.943216</td>\n",
       "      <td>0.576414</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.816901</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.001721</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.509256</td>\n",
       "      <td>0.396229</td>\n",
       "      <td>0.514167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.082176e+10</td>\n",
       "      <td>4.250716e+09</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2178.0</td>\n",
       "      <td>0.840426</td>\n",
       "      <td>0.995952</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.936256</td>\n",
       "      <td>0.576414</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.794521</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.002213</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.489774</td>\n",
       "      <td>0.353913</td>\n",
       "      <td>0.532514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   DL_TRAFFIC_VOLUME  UL_TRAFFIC_VOLUME  Inter_X2_based_HO_prep  \\\n",
       "0       3.779737e+10       3.947172e+09                    15.0   \n",
       "1       3.684898e+10       4.088752e+09                     6.0   \n",
       "2       3.292677e+10       5.016897e+09                     8.0   \n",
       "3       3.021547e+10       5.139107e+09                     9.0   \n",
       "4       3.082176e+10       4.250716e+09                    17.0   \n",
       "\n",
       "   VoLTE_total_traffic  INTRA_FREQ_HO_SR_RATIO  RRC_SR_RATIO  \\\n",
       "0               4727.0                0.809859      0.992427   \n",
       "1               3076.0                0.886792      0.993288   \n",
       "2               3501.0                0.938356      0.994664   \n",
       "3               2275.0                0.860215      0.994819   \n",
       "4               2178.0                0.840426      0.995952   \n",
       "\n",
       "   CELL_AVAILABILITY_RATIO  RACH_Stp_Completion_SR_RATIO  \\\n",
       "0                      1.0                      0.962688   \n",
       "1                      1.0                      0.973207   \n",
       "2                      1.0                      0.966330   \n",
       "3                      1.0                      0.943216   \n",
       "4                      1.0                      0.936256   \n",
       "\n",
       "   Inter_RAT_HO_SR_UTRAN_SRVCC_RATIO  E_RAB_QCI1_DR_RATIO  ...  \\\n",
       "0                           0.576414             0.000000  ...   \n",
       "1                           0.576414             0.000000  ...   \n",
       "2                           0.000000             0.013889  ...   \n",
       "3                           0.576414             0.000000  ...   \n",
       "4                           0.576414             0.000000  ...   \n",
       "\n",
       "   E_UTRAN_Inter_Freq_HO_SR_RATIO  Inter_RAT_HO_SR_GERAN_SRVCC_RATIO  \\\n",
       "0                        0.770642                           0.963636   \n",
       "1                        0.842105                           1.000000   \n",
       "2                        0.931624                           1.000000   \n",
       "3                        0.816901                           0.947368   \n",
       "4                        0.794521                           1.000000   \n",
       "\n",
       "   Inter_RAT_Total_HO_SR_RATIO  E_UTRAN_tot_HO_SR_inter_eNB_X2_RATIO  \\\n",
       "0                     0.963636                              0.400000   \n",
       "1                     1.000000                              0.500000   \n",
       "2                     0.966667                              0.375000   \n",
       "3                     0.947368                              0.777778   \n",
       "4                     1.000000                              0.764706   \n",
       "\n",
       "   E_RAB_DR_RATIO  HOUR  cell  IF_score   AE_loss  STACKING_score  \n",
       "0        0.001761     0     0  0.512958  0.933036        0.537582  \n",
       "1        0.002468     1     0  0.485098  0.633906        0.542922  \n",
       "2        0.003077     2     0  0.536488  1.180561        0.560033  \n",
       "3        0.001721     3     0  0.509256  0.396229        0.514167  \n",
       "4        0.002213     4     0  0.489774  0.353913        0.532514  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ad6fcc",
   "metadata": {},
   "source": [
    "# 5. Save Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6622f36e",
   "metadata": {},
   "source": [
    "## 5.1 Save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c3f2914d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model/IF.joblib']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save model\n",
    "dump(IF,\"model/IF.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "943ba5ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\AE\\assets\n",
      "INFO:tensorflow:Assets written to: model\\Encoder\\assets\n",
      "INFO:tensorflow:Assets written to: model\\Decoder\\assets\n"
     ]
    }
   ],
   "source": [
    "ae.save(\"model\\AE\")\n",
    "encoder.save(\"model\\Encoder\")\n",
    "decoder.save(\"model\\Decoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6b164e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model/AE_IF_stacking.joblib']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save model\n",
    "dump(AE_IF,\"model/AE_IF_stacking.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3f5b01",
   "metadata": {},
   "source": [
    "## 5.2 Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7c0e409a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/KPIs_with_metrics.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2d7f03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "320px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
