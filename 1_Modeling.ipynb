{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bec5f4de",
   "metadata": {},
   "source": [
    "# 0. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04f86b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from joblib import dump\n",
    "\n",
    "# Isolation Forest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# VAE\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.layers import Input, Dense, Lambda, Flatten, Reshape\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import backend as K\n",
    "from keras import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c0c0f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>cell_id</th>\n",
       "      <th>DL_TRAFFIC_VOLUME</th>\n",
       "      <th>UL_TRAFFIC_VOLUME</th>\n",
       "      <th>Inter_X2_based_HO_prep</th>\n",
       "      <th>VoLTE_total_traffic</th>\n",
       "      <th>INTRA_FREQ_HO_SR_RATIO</th>\n",
       "      <th>RRC_SR_RATIO</th>\n",
       "      <th>CELL_AVAILABILITY_RATIO</th>\n",
       "      <th>RACH_Stp_Completion_SR_RATIO</th>\n",
       "      <th>...</th>\n",
       "      <th>DCR_LTE_RATIO</th>\n",
       "      <th>CSSR_LTE_RATIO</th>\n",
       "      <th>LTE_INTER_ENODEB_HOSR_RATIO</th>\n",
       "      <th>E_UTRAN_Inter_Freq_HO_SR_RATIO</th>\n",
       "      <th>Inter_RAT_HO_SR_GERAN_SRVCC_RATIO</th>\n",
       "      <th>Inter_RAT_Total_HO_SR_RATIO</th>\n",
       "      <th>E_UTRAN_tot_HO_SR_inter_eNB_X2_RATIO</th>\n",
       "      <th>E_RAB_DR_RATIO</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>cell</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-05-09 00:00:00</td>\n",
       "      <td>2.226537e+17</td>\n",
       "      <td>3.779737e+10</td>\n",
       "      <td>3.947172e+09</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4727.0</td>\n",
       "      <td>0.809859</td>\n",
       "      <td>0.992427</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.962688</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001761</td>\n",
       "      <td>0.996041</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.770642</td>\n",
       "      <td>0.963636</td>\n",
       "      <td>0.963636</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.001761</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-05-09 01:00:00</td>\n",
       "      <td>2.226537e+17</td>\n",
       "      <td>3.684898e+10</td>\n",
       "      <td>4.088752e+09</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3076.0</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.993288</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.973207</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002468</td>\n",
       "      <td>0.995465</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.002468</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-05-09 02:00:00</td>\n",
       "      <td>2.226537e+17</td>\n",
       "      <td>3.292677e+10</td>\n",
       "      <td>5.016897e+09</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3501.0</td>\n",
       "      <td>0.938356</td>\n",
       "      <td>0.994664</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.966330</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003077</td>\n",
       "      <td>0.996044</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.931624</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.003077</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-05-09 03:00:00</td>\n",
       "      <td>2.226537e+17</td>\n",
       "      <td>3.021547e+10</td>\n",
       "      <td>5.139107e+09</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2275.0</td>\n",
       "      <td>0.860215</td>\n",
       "      <td>0.994819</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.943216</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001721</td>\n",
       "      <td>0.995920</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.816901</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.001721</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-05-09 04:00:00</td>\n",
       "      <td>2.226537e+17</td>\n",
       "      <td>3.082176e+10</td>\n",
       "      <td>4.250716e+09</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2178.0</td>\n",
       "      <td>0.840426</td>\n",
       "      <td>0.995952</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.936256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002213</td>\n",
       "      <td>0.995628</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.794521</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.002213</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 index       cell_id  DL_TRAFFIC_VOLUME  UL_TRAFFIC_VOLUME  \\\n",
       "0  2021-05-09 00:00:00  2.226537e+17       3.779737e+10       3.947172e+09   \n",
       "1  2021-05-09 01:00:00  2.226537e+17       3.684898e+10       4.088752e+09   \n",
       "2  2021-05-09 02:00:00  2.226537e+17       3.292677e+10       5.016897e+09   \n",
       "3  2021-05-09 03:00:00  2.226537e+17       3.021547e+10       5.139107e+09   \n",
       "4  2021-05-09 04:00:00  2.226537e+17       3.082176e+10       4.250716e+09   \n",
       "\n",
       "   Inter_X2_based_HO_prep  VoLTE_total_traffic  INTRA_FREQ_HO_SR_RATIO  \\\n",
       "0                    15.0               4727.0                0.809859   \n",
       "1                     6.0               3076.0                0.886792   \n",
       "2                     8.0               3501.0                0.938356   \n",
       "3                     9.0               2275.0                0.860215   \n",
       "4                    17.0               2178.0                0.840426   \n",
       "\n",
       "   RRC_SR_RATIO  CELL_AVAILABILITY_RATIO  RACH_Stp_Completion_SR_RATIO  ...  \\\n",
       "0      0.992427                      1.0                      0.962688  ...   \n",
       "1      0.993288                      1.0                      0.973207  ...   \n",
       "2      0.994664                      1.0                      0.966330  ...   \n",
       "3      0.994819                      1.0                      0.943216  ...   \n",
       "4      0.995952                      1.0                      0.936256  ...   \n",
       "\n",
       "   DCR_LTE_RATIO  CSSR_LTE_RATIO  LTE_INTER_ENODEB_HOSR_RATIO  \\\n",
       "0       0.001761        0.996041                     0.400000   \n",
       "1       0.002468        0.995465                     0.500000   \n",
       "2       0.003077        0.996044                     0.375000   \n",
       "3       0.001721        0.995920                     0.777778   \n",
       "4       0.002213        0.995628                     0.764706   \n",
       "\n",
       "   E_UTRAN_Inter_Freq_HO_SR_RATIO  Inter_RAT_HO_SR_GERAN_SRVCC_RATIO  \\\n",
       "0                        0.770642                           0.963636   \n",
       "1                        0.842105                           1.000000   \n",
       "2                        0.931624                           1.000000   \n",
       "3                        0.816901                           0.947368   \n",
       "4                        0.794521                           1.000000   \n",
       "\n",
       "   Inter_RAT_Total_HO_SR_RATIO  E_UTRAN_tot_HO_SR_inter_eNB_X2_RATIO  \\\n",
       "0                     0.963636                              0.400000   \n",
       "1                     1.000000                              0.500000   \n",
       "2                     0.966667                              0.375000   \n",
       "3                     0.947368                              0.777778   \n",
       "4                     1.000000                              0.764706   \n",
       "\n",
       "   E_RAB_DR_RATIO  HOUR  cell  \n",
       "0        0.001761     0     0  \n",
       "1        0.002468     1     0  \n",
       "2        0.003077     2     0  \n",
       "3        0.001721     3     0  \n",
       "4        0.002213     4     0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/cleaned_KPIs.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d75cb9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['cell_id','index'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8caf7790",
   "metadata": {},
   "source": [
    "# 1. Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "beba0e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "IF=IsolationForest(n_estimators=150, \n",
    "                      max_samples ='auto', \n",
    "                      max_features=1,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1c33a46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.51295825, 0.48509757, 0.53648751, 0.50925568, 0.48977436,\n",
       "       0.52157804, 0.50460632, 0.47403398, 0.47869537, 0.4786467 ,\n",
       "       0.46769137, 0.46808774, 0.47676634, 0.48726571, 0.48067503,\n",
       "       0.50214502, 0.47844321, 0.47284323, 0.46897991, 0.46007395])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IF.fit(df)\n",
    "# score_samples = - score  \n",
    "IF_score = -1 * IF.score_samples(df)\n",
    "IF_score[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158f3a5b",
   "metadata": {},
   "source": [
    "# 2. VAE\n",
    "\n",
    "[keras - Variational AutoEncoder 官方代码范例(复杂)](https://keras.io/examples/generative/vae/)\n",
    "\n",
    "[keras - AE/VAE 相对简单的代码构建](https://blog.keras.io/building-autoencoders-in-keras.html)\n",
    "\n",
    "[keras - 中等程度AVE 但是有点乱](https://github.com/keras-team/keras/blob/2c8d1d03599cc03243bce8f07ed9c4a3d5f384f9/examples/variational_autoencoder.py)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[中文VAE理论+代码](https://blog.csdn.net/weixin_37737254/article/details/102920263)\n",
    "\n",
    "[keras - 函数式API](https://keras.io/guides/functional_api/)\n",
    "\n",
    "[keras - Conv1D](https://keras-zh.readthedocs.io/layers/convolutional/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3164441",
   "metadata": {},
   "source": [
    "## 2.1 Build model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d99a10",
   "metadata": {},
   "source": [
    "**(1) Standardize** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945523ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled = StandardScaler().fit_transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646bc0fe",
   "metadata": {},
   "source": [
    "**(2) Define sampling function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "368be1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(args):\n",
    "    z_mean, z_log_sigma = args\n",
    "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim),\n",
    "                              mean=0., stddev=0.1)\n",
    "    return z_mean + K.exp(z_log_sigma) * epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8f45fb",
   "metadata": {},
   "source": [
    "**(3) Build Encoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9d03e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 20)]         0           []                               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 16)           336         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 4)            68          ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " z_mean (Dense)                 (None, 2)            10          ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " z_log_var (Dense)              (None, 2)            10          ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 2)            0           ['z_mean[0][0]',                 \n",
      "                                                                  'z_log_var[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 424\n",
      "Trainable params: 424\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "original_dim = df.shape[1]\n",
    "intermediate_dim = 32\n",
    "latent_dim = 2\n",
    "\n",
    "# encoder input\n",
    "inputs = keras.Input(shape=(original_dim,))\n",
    "x = layers.Dense(16, activation=\"relu\")(inputs)\n",
    "x = layers.Dense(4, activation=\"relu\")(x)\n",
    "\n",
    "# the output of encoder\n",
    "z_mean      = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_sigma = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "z           = layers.Lambda(sampling)([z_mean, z_log_sigma])\n",
    "\n",
    "# Create encoder\n",
    "encoder = keras.Model(inputs, [z_mean, z_log_sigma, z], name='encoder')\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a86f8c",
   "metadata": {},
   "source": [
    "**(4) Build Decoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12179934",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " z_sampling (InputLayer)     [(None, 2)]               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4)                 12        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 16)                80        \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 20)                340       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 432\n",
      "Trainable params: 432\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create decoder\n",
    "latent_inputs = keras.Input(shape=(latent_dim,), name='z_sampling')\n",
    "x = layers.Dense(4, activation='relu')(latent_inputs)\n",
    "x = layers.Dense(16,activation='relu')(x)\n",
    "outputs = layers.Dense(original_dim, activation='sigmoid')(x)\n",
    "decoder = keras.Model(latent_inputs, outputs, name='decoder')\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adb2e38",
   "metadata": {},
   "source": [
    "**(5) Build Variational AutoEncoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55cd58bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate VAE model\n",
    "outputs = decoder(encoder(inputs)[2])\n",
    "vae = keras.Model(inputs, outputs, name='vae_mlp')\n",
    "\n",
    "# Define Loss Function\n",
    "reconstruction_loss = keras.losses.mean_squared_error(inputs, outputs)\n",
    "kl_loss = -0.5 * K.sum(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma), axis=-1)\n",
    "vae_loss = K.mean(reconstruction_loss + 0.01* kl_loss) \n",
    "\n",
    "# Optimiser \n",
    "adam = keras.optimizers.Adam(learning_rate=0.001)\n",
    "# Add loss function\n",
    "vae.add_loss(vae_loss)\n",
    "vae.compile(optimizer=adam)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375b054b",
   "metadata": {},
   "source": [
    "Notices:\n",
    "- weight of kl_loss?  [theoretical insight](https://stats.stackexchange.com/questions/332179/how-to-weight-kld-loss-vs-reconstruction-loss-in-variational-auto-encoder) + [a more specific example](https://stats.stackexchange.com/questions/341954/balancing-reconstruction-vs-kl-loss-variational-autoencoder)\n",
    "- reconsctruction_loss : if use `binary_crossentropy`( $BCE(y,p)=-y.log(p)-(1-y).log(1-p)$ ), the input value should be in 0~1. In our case, since we use 'StandardScaler', we'd better use `mse`, otherwise, when training the model, the loss becomes -inf "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4a3e53",
   "metadata": {},
   "source": [
    "**(6) Train model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96e63ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "65/65 [==============================] - 1s 5ms/step - loss: 1.2260 - val_loss: 1.1705\n",
      "Epoch 2/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.0934 - val_loss: 1.0361\n",
      "Epoch 3/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.0082 - val_loss: 0.9867\n",
      "Epoch 4/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.9718 - val_loss: 0.9576\n",
      "Epoch 5/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.9474 - val_loss: 0.9382\n",
      "Epoch 6/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.9314 - val_loss: 0.9247\n",
      "Epoch 7/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.9173 - val_loss: 0.9107\n",
      "Epoch 8/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.9011 - val_loss: 0.8915\n",
      "Epoch 9/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.8834 - val_loss: 0.8761\n",
      "Epoch 10/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.8707 - val_loss: 0.8645\n",
      "Epoch 11/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.8612 - val_loss: 0.8542\n",
      "Epoch 12/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.8490 - val_loss: 0.8440\n",
      "Epoch 13/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.8418 - val_loss: 0.8336\n",
      "Epoch 14/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.8290 - val_loss: 0.8244\n",
      "Epoch 15/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.8201 - val_loss: 0.8162\n",
      "Epoch 16/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.8142 - val_loss: 0.8112\n",
      "Epoch 17/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.8096 - val_loss: 0.8073\n",
      "Epoch 18/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.8059 - val_loss: 0.8042\n",
      "Epoch 19/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.8045 - val_loss: 0.8019\n",
      "Epoch 20/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.8002 - val_loss: 0.7997\n",
      "Epoch 21/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7996 - val_loss: 0.7980\n",
      "Epoch 22/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7982 - val_loss: 0.7963\n",
      "Epoch 23/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7952 - val_loss: 0.7947\n",
      "Epoch 24/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7946 - val_loss: 0.7935\n",
      "Epoch 25/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7926 - val_loss: 0.7925\n",
      "Epoch 26/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7924 - val_loss: 0.7914\n",
      "Epoch 27/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7915 - val_loss: 0.7904\n",
      "Epoch 28/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7898 - val_loss: 0.7896\n",
      "Epoch 29/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7923 - val_loss: 0.7886\n",
      "Epoch 30/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7886 - val_loss: 0.7881\n",
      "Epoch 31/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7879 - val_loss: 0.7879\n",
      "Epoch 32/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7873 - val_loss: 0.7869\n",
      "Epoch 33/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7871 - val_loss: 0.7865\n",
      "Epoch 34/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7873 - val_loss: 0.7856\n",
      "Epoch 35/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7877 - val_loss: 0.7856\n",
      "Epoch 36/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7855 - val_loss: 0.7848\n",
      "Epoch 37/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7859 - val_loss: 0.7846\n",
      "Epoch 38/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7867 - val_loss: 0.7841\n",
      "Epoch 39/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7844 - val_loss: 0.7842\n",
      "Epoch 40/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7838 - val_loss: 0.7833\n",
      "Epoch 41/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7848 - val_loss: 0.7829\n",
      "Epoch 42/500\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7837 - val_loss: 0.7827\n",
      "Epoch 43/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7857 - val_loss: 0.7826\n",
      "Epoch 44/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7850 - val_loss: 0.7820\n",
      "Epoch 45/500\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7826 - val_loss: 0.7820\n",
      "Epoch 46/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7819 - val_loss: 0.7817\n",
      "Epoch 47/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7828 - val_loss: 0.7816\n",
      "Epoch 48/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7840 - val_loss: 0.7812\n",
      "Epoch 49/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7814 - val_loss: 0.7811\n",
      "Epoch 50/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7808 - val_loss: 0.7807\n",
      "Epoch 51/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7813 - val_loss: 0.7808\n",
      "Epoch 52/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7824 - val_loss: 0.7802\n",
      "Epoch 53/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7806 - val_loss: 0.7802\n",
      "Epoch 54/500\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7793 - val_loss: 0.7805\n",
      "Epoch 55/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7802 - val_loss: 0.7800\n",
      "Epoch 56/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7802 - val_loss: 0.7797\n",
      "Epoch 57/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7816 - val_loss: 0.7793\n",
      "Epoch 58/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7794 - val_loss: 0.7795\n",
      "Epoch 59/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7803 - val_loss: 0.7790\n",
      "Epoch 60/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7787 - val_loss: 0.7789\n",
      "Epoch 61/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7821 - val_loss: 0.7789\n",
      "Epoch 62/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7801 - val_loss: 0.7787\n",
      "Epoch 63/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7792 - val_loss: 0.7784\n",
      "Epoch 64/500\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7781 - val_loss: 0.7784\n",
      "Epoch 65/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7784 - val_loss: 0.7784\n",
      "Epoch 66/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7776 - val_loss: 0.7783\n",
      "Epoch 67/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7781 - val_loss: 0.7777\n",
      "Epoch 68/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7778 - val_loss: 0.7774\n",
      "Epoch 69/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7772 - val_loss: 0.7771\n",
      "Epoch 70/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7776 - val_loss: 0.7770\n",
      "Epoch 71/500\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7776 - val_loss: 0.7769\n",
      "Epoch 72/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7771 - val_loss: 0.7766\n",
      "Epoch 73/500\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7771 - val_loss: 0.7773\n",
      "Epoch 74/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7768 - val_loss: 0.7767\n",
      "Epoch 75/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7780 - val_loss: 0.7767\n",
      "Epoch 76/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7773 - val_loss: 0.7764\n",
      "Epoch 77/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7761 - val_loss: 0.7759\n",
      "Epoch 78/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7759 - val_loss: 0.7757\n",
      "Epoch 79/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7763 - val_loss: 0.7756\n",
      "Epoch 80/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7756 - val_loss: 0.7754\n",
      "Epoch 81/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7748 - val_loss: 0.7755\n",
      "Epoch 82/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7749 - val_loss: 0.7755\n",
      "Epoch 83/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7749 - val_loss: 0.7755\n",
      "Epoch 84/500\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7775 - val_loss: 0.7753\n",
      "Epoch 85/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7752 - val_loss: 0.7753\n",
      "Epoch 86/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7776 - val_loss: 0.7752\n",
      "Epoch 87/500\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7774 - val_loss: 0.7752\n",
      "Epoch 88/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7779 - val_loss: 0.7748\n",
      "Epoch 89/500\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7765 - val_loss: 0.7735\n",
      "Epoch 90/500\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7717 - val_loss: 0.7713\n",
      "Epoch 91/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7717 - val_loss: 0.7713\n",
      "Epoch 92/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7710 - val_loss: 0.7713\n",
      "Epoch 93/500\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7716 - val_loss: 0.7709\n",
      "Epoch 94/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7723 - val_loss: 0.7709\n",
      "Epoch 95/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7716 - val_loss: 0.7707\n",
      "Epoch 96/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7706 - val_loss: 0.7706\n",
      "Epoch 97/500\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7707 - val_loss: 0.7708\n",
      "Epoch 98/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7707 - val_loss: 0.7706\n",
      "Epoch 99/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7710 - val_loss: 0.7707\n",
      "Epoch 100/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7702 - val_loss: 0.7704\n",
      "Epoch 101/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7706 - val_loss: 0.7703\n",
      "Epoch 102/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7700 - val_loss: 0.7706\n",
      "Epoch 103/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7708 - val_loss: 0.7704\n",
      "Epoch 104/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7710 - val_loss: 0.7701\n",
      "Epoch 105/500\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7707 - val_loss: 0.7700\n",
      "Epoch 106/500\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7693 - val_loss: 0.7698\n",
      "Epoch 107/500\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7695 - val_loss: 0.7704\n",
      "Epoch 108/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7709 - val_loss: 0.7701\n",
      "Epoch 109/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7707 - val_loss: 0.7700\n",
      "Epoch 110/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7699 - val_loss: 0.7699\n",
      "Epoch 111/500\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7705 - val_loss: 0.7703\n",
      "Epoch 112/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7697 - val_loss: 0.7700\n",
      "Epoch 113/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7708 - val_loss: 0.7696\n",
      "Epoch 114/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7700 - val_loss: 0.7698\n",
      "Epoch 115/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7692 - val_loss: 0.7699\n",
      "Epoch 116/500\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7708 - val_loss: 0.7698\n",
      "Epoch 117/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7692 - val_loss: 0.7696\n",
      "Epoch 118/500\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7698 - val_loss: 0.7695\n",
      "Epoch 119/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7694 - val_loss: 0.7692\n",
      "Epoch 120/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7705 - val_loss: 0.7694\n",
      "Epoch 121/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7690 - val_loss: 0.7694\n",
      "Epoch 122/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7704 - val_loss: 0.7693\n",
      "Epoch 123/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7715 - val_loss: 0.7697\n",
      "Epoch 124/500\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7710 - val_loss: 0.7694\n",
      "Epoch 125/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7689 - val_loss: 0.7690\n",
      "Epoch 126/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7693 - val_loss: 0.7690\n",
      "Epoch 127/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7685 - val_loss: 0.7688\n",
      "Epoch 128/500\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7687 - val_loss: 0.7688\n",
      "Epoch 129/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7690 - val_loss: 0.7690\n",
      "Epoch 130/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7703 - val_loss: 0.7696\n",
      "Epoch 131/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7691 - val_loss: 0.7691\n",
      "Epoch 132/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7697 - val_loss: 0.7691\n",
      "Epoch 133/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7703 - val_loss: 0.7689\n",
      "Epoch 134/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7692 - val_loss: 0.7690\n",
      "Epoch 135/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7681 - val_loss: 0.7687\n",
      "Epoch 136/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7692 - val_loss: 0.7688\n",
      "Epoch 137/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7694 - val_loss: 0.7686\n",
      "Epoch 138/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7691 - val_loss: 0.7687\n",
      "Epoch 139/500\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7689 - val_loss: 0.7684\n",
      "Epoch 140/500\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7710 - val_loss: 0.7687\n",
      "Epoch 141/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7690 - val_loss: 0.7689\n",
      "Epoch 142/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7710 - val_loss: 0.7684\n",
      "Epoch 143/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7687 - val_loss: 0.7686\n",
      "Epoch 144/500\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7686 - val_loss: 0.7683\n",
      "Epoch 145/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7687 - val_loss: 0.7688\n",
      "Epoch 146/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7684 - val_loss: 0.7685\n",
      "Epoch 147/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7689 - val_loss: 0.7681\n",
      "Epoch 148/500\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7687 - val_loss: 0.7683\n",
      "Epoch 149/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7685 - val_loss: 0.7684\n",
      "Epoch 150/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7681 - val_loss: 0.7684\n",
      "Epoch 151/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7682 - val_loss: 0.7685\n",
      "Epoch 152/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7684 - val_loss: 0.7682\n",
      "Epoch 153/500\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7677 - val_loss: 0.7681\n",
      "Epoch 154/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7683 - val_loss: 0.7680\n",
      "Epoch 155/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7697 - val_loss: 0.7678\n",
      "Epoch 156/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7683 - val_loss: 0.7680\n",
      "Epoch 157/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7677 - val_loss: 0.7682\n",
      "Epoch 158/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7680 - val_loss: 0.7678\n",
      "Epoch 159/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7684 - val_loss: 0.7680\n",
      "Epoch 160/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7675 - val_loss: 0.7681\n",
      "Epoch 161/500\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.7698 - val_loss: 0.7679\n",
      "Epoch 162/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7674 - val_loss: 0.7678\n",
      "Epoch 163/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7687 - val_loss: 0.7676\n",
      "Epoch 164/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7679 - val_loss: 0.7676\n",
      "Epoch 165/500\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7679 - val_loss: 0.7678\n",
      "Epoch 166/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7685 - val_loss: 0.7680\n",
      "Epoch 167/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7686 - val_loss: 0.7674\n",
      "Epoch 168/500\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7678 - val_loss: 0.7677\n",
      "Epoch 169/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7676 - val_loss: 0.7674\n",
      "Epoch 170/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7675 - val_loss: 0.7679\n",
      "Epoch 171/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7700 - val_loss: 0.7675\n",
      "Epoch 172/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7667 - val_loss: 0.7674\n",
      "Epoch 173/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7697 - val_loss: 0.7674\n",
      "Epoch 174/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7694 - val_loss: 0.7674\n",
      "Epoch 175/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7682 - val_loss: 0.7675\n",
      "Epoch 176/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7699 - val_loss: 0.7675\n",
      "Epoch 177/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7669 - val_loss: 0.7681\n",
      "Epoch 178/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7672 - val_loss: 0.7672\n",
      "Epoch 179/500\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.7678 - val_loss: 0.7675\n",
      "Epoch 180/500\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7668 - val_loss: 0.7673\n",
      "Epoch 181/500\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.7671 - val_loss: 0.7677\n",
      "Epoch 182/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7686 - val_loss: 0.7672\n",
      "Epoch 183/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7681 - val_loss: 0.7670\n",
      "Epoch 184/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7668 - val_loss: 0.7670\n",
      "Epoch 185/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7670 - val_loss: 0.7671\n",
      "Epoch 186/500\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7674 - val_loss: 0.7671\n",
      "Epoch 187/500\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7667 - val_loss: 0.7669\n",
      "Epoch 188/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7682 - val_loss: 0.7666\n",
      "Epoch 189/500\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7670 - val_loss: 0.7666\n",
      "Epoch 190/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7665 - val_loss: 0.7670\n",
      "Epoch 191/500\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.7667 - val_loss: 0.7665\n",
      "Epoch 192/500\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.7672 - val_loss: 0.7665\n",
      "Epoch 193/500\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.7674 - val_loss: 0.7667\n",
      "Epoch 194/500\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.7658 - val_loss: 0.7663\n",
      "Epoch 195/500\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.7639 - val_loss: 0.7599\n",
      "Epoch 196/500\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.7595 - val_loss: 0.7598\n",
      "Epoch 197/500\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7594 - val_loss: 0.7590\n",
      "Epoch 198/500\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7597 - val_loss: 0.7587\n",
      "Epoch 199/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7610 - val_loss: 0.7583\n",
      "Epoch 200/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7589 - val_loss: 0.7579\n",
      "Epoch 201/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7575 - val_loss: 0.7579\n",
      "Epoch 202/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7572 - val_loss: 0.7574\n",
      "Epoch 203/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7574 - val_loss: 0.7576\n",
      "Epoch 204/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7570 - val_loss: 0.7576\n",
      "Epoch 205/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7628 - val_loss: 0.7570\n",
      "Epoch 206/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7617 - val_loss: 0.7571\n",
      "Epoch 207/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7568 - val_loss: 0.7568\n",
      "Epoch 208/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7562 - val_loss: 0.7570\n",
      "Epoch 209/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7561 - val_loss: 0.7571\n",
      "Epoch 210/500\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7565 - val_loss: 0.7567\n",
      "Epoch 211/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7588 - val_loss: 0.7567\n",
      "Epoch 212/500\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7559 - val_loss: 0.7569\n",
      "Epoch 213/500\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.7570 - val_loss: 0.7566\n",
      "Epoch 214/500\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.7565 - val_loss: 0.7565\n",
      "Epoch 215/500\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.7582 - val_loss: 0.7566\n",
      "Epoch 216/500\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.7573 - val_loss: 0.7564\n",
      "Epoch 217/500\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7558 - val_loss: 0.7562\n",
      "Epoch 218/500\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7571 - val_loss: 0.7562\n",
      "Epoch 219/500\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7582 - val_loss: 0.7565\n",
      "Epoch 220/500\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7562 - val_loss: 0.7560\n",
      "Epoch 221/500\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.7576 - val_loss: 0.7560\n",
      "Epoch 222/500\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7562 - val_loss: 0.7560\n",
      "Epoch 223/500\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7564 - val_loss: 0.7558\n",
      "Epoch 224/500\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7563 - val_loss: 0.7560\n",
      "Epoch 225/500\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7569 - val_loss: 0.7560\n",
      "Epoch 226/500\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7559 - val_loss: 0.7561\n",
      "Epoch 227/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7559 - val_loss: 0.7562\n",
      "Epoch 228/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7601 - val_loss: 0.7561\n",
      "Epoch 229/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7566 - val_loss: 0.7555\n",
      "Epoch 230/500\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7550 - val_loss: 0.7559\n",
      "Epoch 231/500\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7573 - val_loss: 0.7555\n",
      "Epoch 232/500\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7557 - val_loss: 0.7558\n",
      "Epoch 233/500\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7563 - val_loss: 0.7558\n",
      "Epoch 234/500\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.7560 - val_loss: 0.7557\n",
      "Epoch 235/500\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.7561 - val_loss: 0.7556\n",
      "Epoch 236/500\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7556 - val_loss: 0.7557\n",
      "Epoch 237/500\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7578 - val_loss: 0.7554\n",
      "Epoch 238/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7595 - val_loss: 0.7557\n",
      "Epoch 239/500\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7555 - val_loss: 0.7552\n",
      "Epoch 240/500\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7578 - val_loss: 0.7553\n",
      "Epoch 241/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7648 - val_loss: 0.7553\n",
      "Epoch 242/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7554 - val_loss: 0.7555\n",
      "Epoch 243/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7547 - val_loss: 0.7553\n",
      "Epoch 244/500\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7555 - val_loss: 0.7558\n",
      "Epoch 245/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7553 - val_loss: 0.7551\n",
      "Epoch 246/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7560 - val_loss: 0.7551\n",
      "Epoch 247/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7569 - val_loss: 0.7553\n",
      "Epoch 248/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7554 - val_loss: 0.7555\n",
      "Epoch 249/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7561 - val_loss: 0.7554\n",
      "Epoch 250/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7563 - val_loss: 0.7551\n",
      "Epoch 251/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7548 - val_loss: 0.7551\n",
      "Epoch 252/500\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7553 - val_loss: 0.7551\n",
      "Epoch 253/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7545 - val_loss: 0.7549\n",
      "Epoch 254/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7550 - val_loss: 0.7549\n",
      "Epoch 255/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7551 - val_loss: 0.7549\n",
      "Epoch 256/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7550 - val_loss: 0.7551\n",
      "Epoch 257/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7568 - val_loss: 0.7549\n",
      "Epoch 258/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7551 - val_loss: 0.7552\n",
      "Epoch 259/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7550 - val_loss: 0.7547\n",
      "Epoch 260/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7551 - val_loss: 0.7549\n",
      "Epoch 261/500\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7545 - val_loss: 0.7549\n",
      "Epoch 262/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7553 - val_loss: 0.7552\n",
      "Epoch 263/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7551 - val_loss: 0.7546\n",
      "Epoch 264/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7559 - val_loss: 0.7550\n",
      "Epoch 265/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7556 - val_loss: 0.7547\n",
      "Epoch 266/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7576 - val_loss: 0.7545\n",
      "Epoch 267/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7547 - val_loss: 0.7543\n",
      "Epoch 268/500\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7541 - val_loss: 0.7546\n",
      "Epoch 269/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7544 - val_loss: 0.7544\n",
      "Epoch 270/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7542 - val_loss: 0.7544\n",
      "Epoch 271/500\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7563 - val_loss: 0.7545\n",
      "Epoch 272/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7542 - val_loss: 0.7544\n",
      "Epoch 273/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7533 - val_loss: 0.7544\n",
      "Epoch 274/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7548 - val_loss: 0.7542\n",
      "Epoch 275/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7543 - val_loss: 0.7545\n",
      "Epoch 276/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7554 - val_loss: 0.7544\n",
      "Epoch 277/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7546 - val_loss: 0.7545\n",
      "Epoch 278/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7539 - val_loss: 0.7541\n",
      "Epoch 279/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7540 - val_loss: 0.7546\n",
      "Epoch 280/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7549 - val_loss: 0.7546\n",
      "Epoch 281/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7548 - val_loss: 0.7546\n",
      "Epoch 282/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7555 - val_loss: 0.7552\n",
      "Epoch 283/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7571 - val_loss: 0.7547\n",
      "Epoch 284/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7545 - val_loss: 0.7542\n",
      "Epoch 285/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7541 - val_loss: 0.7544\n",
      "Epoch 286/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7546 - val_loss: 0.7545\n",
      "Epoch 287/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7537 - val_loss: 0.7544\n",
      "Epoch 288/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7534 - val_loss: 0.7539\n",
      "Epoch 289/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7551 - val_loss: 0.7540\n",
      "Epoch 290/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7549 - val_loss: 0.7549\n",
      "Epoch 291/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7538 - val_loss: 0.7544\n",
      "Epoch 292/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7556 - val_loss: 0.7542\n",
      "Epoch 293/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7542 - val_loss: 0.7539\n",
      "Epoch 294/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7539 - val_loss: 0.7541\n",
      "Epoch 295/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7558 - val_loss: 0.7538\n",
      "Epoch 296/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7532 - val_loss: 0.7540\n",
      "Epoch 297/500\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7535 - val_loss: 0.7540\n",
      "Epoch 298/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7542 - val_loss: 0.7539\n",
      "Epoch 299/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7536 - val_loss: 0.7539\n",
      "Epoch 300/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7560 - val_loss: 0.7541\n",
      "Epoch 301/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7597 - val_loss: 0.7538\n",
      "Epoch 302/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7541 - val_loss: 0.7538\n",
      "Epoch 303/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7564 - val_loss: 0.7539\n",
      "Epoch 304/500\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7539 - val_loss: 0.7537\n",
      "Epoch 305/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7549 - val_loss: 0.7539\n",
      "Epoch 306/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7561 - val_loss: 0.7539\n",
      "Epoch 307/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7541 - val_loss: 0.7541\n",
      "Epoch 308/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7551 - val_loss: 0.7543\n",
      "Epoch 309/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7562 - val_loss: 0.7537\n",
      "Epoch 310/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7545 - val_loss: 0.7536\n",
      "Epoch 311/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7546 - val_loss: 0.7539\n",
      "Epoch 312/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7540 - val_loss: 0.7539\n",
      "Epoch 313/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7539 - val_loss: 0.7537\n",
      "Epoch 314/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7538 - val_loss: 0.7537\n",
      "Epoch 315/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7538 - val_loss: 0.7537\n",
      "Epoch 316/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7549 - val_loss: 0.7539\n",
      "Epoch 317/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7553 - val_loss: 0.7540\n",
      "Epoch 318/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7540 - val_loss: 0.7535\n",
      "Epoch 319/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7530 - val_loss: 0.7533\n",
      "Epoch 320/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7541 - val_loss: 0.7537\n",
      "Epoch 321/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7591 - val_loss: 0.7533\n",
      "Epoch 322/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7558 - val_loss: 0.7536\n",
      "Epoch 323/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7543 - val_loss: 0.7537\n",
      "Epoch 324/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7534 - val_loss: 0.7537\n",
      "Epoch 325/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7533 - val_loss: 0.7536\n",
      "Epoch 326/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7543 - val_loss: 0.7531\n",
      "Epoch 327/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7553 - val_loss: 0.7536\n",
      "Epoch 328/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7543 - val_loss: 0.7536\n",
      "Epoch 329/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7538 - val_loss: 0.7533\n",
      "Epoch 330/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7526 - val_loss: 0.7534\n",
      "Epoch 331/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7549 - val_loss: 0.7533\n",
      "Epoch 332/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7539 - val_loss: 0.7530\n",
      "Epoch 333/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7534 - val_loss: 0.7533\n",
      "Epoch 334/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7534 - val_loss: 0.7537\n",
      "Epoch 335/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7542 - val_loss: 0.7536\n",
      "Epoch 336/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7532 - val_loss: 0.7532\n",
      "Epoch 337/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7533 - val_loss: 0.7532\n",
      "Epoch 338/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7533 - val_loss: 0.7531\n",
      "Epoch 339/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7537 - val_loss: 0.7531\n",
      "Epoch 340/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7526 - val_loss: 0.7533\n",
      "Epoch 341/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7532 - val_loss: 0.7529\n",
      "Epoch 342/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7531 - val_loss: 0.7533\n",
      "Epoch 343/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7540 - val_loss: 0.7530\n",
      "Epoch 344/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7536 - val_loss: 0.7534\n",
      "Epoch 345/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7532 - val_loss: 0.7532\n",
      "Epoch 346/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7529 - val_loss: 0.7534\n",
      "Epoch 347/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7534 - val_loss: 0.7529\n",
      "Epoch 348/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7533 - val_loss: 0.7530\n",
      "Epoch 349/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7552 - val_loss: 0.7530\n",
      "Epoch 350/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7527 - val_loss: 0.7530\n",
      "Epoch 351/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7548 - val_loss: 0.7528\n",
      "Epoch 352/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7523 - val_loss: 0.7526\n",
      "Epoch 353/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7561 - val_loss: 0.7528\n",
      "Epoch 354/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7530 - val_loss: 0.7528\n",
      "Epoch 355/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7554 - val_loss: 0.7530\n",
      "Epoch 356/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7528 - val_loss: 0.7527\n",
      "Epoch 357/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7537 - val_loss: 0.7529\n",
      "Epoch 358/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7544 - val_loss: 0.7529\n",
      "Epoch 359/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7528 - val_loss: 0.7530\n",
      "Epoch 360/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7527 - val_loss: 0.7525\n",
      "Epoch 361/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7537 - val_loss: 0.7526\n",
      "Epoch 362/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7549 - val_loss: 0.7532\n",
      "Epoch 363/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7532 - val_loss: 0.7527\n",
      "Epoch 364/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7531 - val_loss: 0.7531\n",
      "Epoch 365/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7526 - val_loss: 0.7526\n",
      "Epoch 366/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7544 - val_loss: 0.7528\n",
      "Epoch 367/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7547 - val_loss: 0.7527\n",
      "Epoch 368/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7525 - val_loss: 0.7526\n",
      "Epoch 369/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7536 - val_loss: 0.7524\n",
      "Epoch 370/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7527 - val_loss: 0.7523\n",
      "Epoch 371/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7543 - val_loss: 0.7527\n",
      "Epoch 372/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7518 - val_loss: 0.7527\n",
      "Epoch 373/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7520 - val_loss: 0.7525\n",
      "Epoch 374/500\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7550 - val_loss: 0.7524\n",
      "Epoch 375/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7535 - val_loss: 0.7524\n",
      "Epoch 376/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7532 - val_loss: 0.7526\n",
      "Epoch 377/500\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7530 - val_loss: 0.7526\n",
      "Epoch 378/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7532 - val_loss: 0.7523\n",
      "Epoch 379/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7522 - val_loss: 0.7521\n",
      "Epoch 380/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7516 - val_loss: 0.7523\n",
      "Epoch 381/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7529 - val_loss: 0.7529\n",
      "Epoch 382/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7532 - val_loss: 0.7535\n",
      "Epoch 383/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7527 - val_loss: 0.7527\n",
      "Epoch 384/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7525 - val_loss: 0.7525\n",
      "Epoch 385/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7517 - val_loss: 0.7525\n",
      "Epoch 386/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7522 - val_loss: 0.7523\n",
      "Epoch 387/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7528 - val_loss: 0.7521\n",
      "Epoch 388/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7535 - val_loss: 0.7521\n",
      "Epoch 389/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7518 - val_loss: 0.7522\n",
      "Epoch 390/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7536 - val_loss: 0.7520\n",
      "Epoch 391/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7522 - val_loss: 0.7524\n",
      "Epoch 392/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7517 - val_loss: 0.7523\n",
      "Epoch 393/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7523 - val_loss: 0.7523\n",
      "Epoch 394/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7542 - val_loss: 0.7518\n",
      "Epoch 395/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7560 - val_loss: 0.7522\n",
      "Epoch 396/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7519 - val_loss: 0.7520\n",
      "Epoch 397/500\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7529 - val_loss: 0.7521\n",
      "Epoch 398/500\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7524 - val_loss: 0.7519\n",
      "Epoch 399/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7534 - val_loss: 0.7520\n",
      "Epoch 400/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7518 - val_loss: 0.7521\n",
      "Epoch 401/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7515 - val_loss: 0.7520\n",
      "Epoch 402/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7517 - val_loss: 0.7519\n",
      "Epoch 403/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7524 - val_loss: 0.7517\n",
      "Epoch 404/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7514 - val_loss: 0.7520\n",
      "Epoch 405/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7529 - val_loss: 0.7520\n",
      "Epoch 406/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7514 - val_loss: 0.7519\n",
      "Epoch 407/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7527 - val_loss: 0.7522\n",
      "Epoch 408/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7515 - val_loss: 0.7517\n",
      "Epoch 409/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7521 - val_loss: 0.7518\n",
      "Epoch 410/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7522 - val_loss: 0.7518\n",
      "Epoch 411/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7515 - val_loss: 0.7520\n",
      "Epoch 412/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7518 - val_loss: 0.7520\n",
      "Epoch 413/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7519 - val_loss: 0.7516\n",
      "Epoch 414/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7525 - val_loss: 0.7518\n",
      "Epoch 415/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7519 - val_loss: 0.7520\n",
      "Epoch 416/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7511 - val_loss: 0.7519\n",
      "Epoch 417/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7519 - val_loss: 0.7520\n",
      "Epoch 418/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7522 - val_loss: 0.7514\n",
      "Epoch 419/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7508 - val_loss: 0.7516\n",
      "Epoch 420/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7518 - val_loss: 0.7520\n",
      "Epoch 421/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7530 - val_loss: 0.7522\n",
      "Epoch 422/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7531 - val_loss: 0.7516\n",
      "Epoch 423/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7519 - val_loss: 0.7516\n",
      "Epoch 424/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7523 - val_loss: 0.7516\n",
      "Epoch 425/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7525 - val_loss: 0.7519\n",
      "Epoch 426/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7519 - val_loss: 0.7519\n",
      "Epoch 427/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7516 - val_loss: 0.7519\n",
      "Epoch 428/500\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7532 - val_loss: 0.7516\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23e445f25c8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 500\n",
    "batch_size = 128\n",
    "callback = EarlyStopping(monitor='val_loss',patience=10)\n",
    "\n",
    "# Train model\n",
    "vae.fit(df_scaled, df_scaled,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(df_scaled, df_scaled),\n",
    "        shuffle=True,\n",
    "#         verbose=False,\n",
    "        callbacks=[callback]\n",
    "       )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ade81d5",
   "metadata": {},
   "source": [
    "## 2.2 [Detect Anomaly](https://towardsdatascience.com/hands-on-anomaly-detection-with-variational-autoencoders-d4044672acd5)\n",
    "Detect anomaly by finding those who have a high reconstruction loss.\n",
    "\n",
    "\n",
    "Steps:\n",
    "1. Measure error between the original train (clean/normal) set and the output of the model, and generate an error vector representing the error term of each sample.\n",
    "\n",
    "2. Find a relatively extreme value on that vector to use as your error threshold.\n",
    "\n",
    "3. Run the model over the test or real data, in which anomalies are probably mixed with normal data.\n",
    "\n",
    "4. Measure the reconstruction error and mark samples that exhibit an error term higher than the error threshold as anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c710e729",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(original,reconstructed):\n",
    "    return np.mean((original-reconstructed)**2,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aaf1a17a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9548081 , 0.73358319, 1.40899536, 0.40172662, 0.39875465,\n",
       "       1.22539572, 4.24734052, 1.04168809, 1.48420087, 1.76684453,\n",
       "       0.91322416, 0.37648604, 0.73476575, 1.40290654, 0.94696274,\n",
       "       1.27051636, 1.24073557, 0.48180151, 0.81719654, 0.78864816])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "pred  = vae.predict(df_scaled)\n",
    "\n",
    "VAE_loss = mse(df_scaled,pred)\n",
    "VAE_loss[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2806fe",
   "metadata": {},
   "source": [
    "# 3. VAE + IF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d583e5fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.49713367,  0.6343895 ],\n",
       "        [-0.47102445,  0.651857  ],\n",
       "        [-0.8752914 ,  0.7799051 ],\n",
       "        ...,\n",
       "        [ 0.8411997 , -0.09197786],\n",
       "        [ 0.8411997 , -0.09197786],\n",
       "        [ 0.92201024, -0.00449666]], dtype=float32),\n",
       " array([[-0.42058647, -1.0437922 ],\n",
       "        [-0.43079686, -1.0465313 ],\n",
       "        [-0.20457768, -1.0476806 ],\n",
       "        ...,\n",
       "        [-1.1643947 , -0.62823445],\n",
       "        [-1.1643947 , -0.62823445],\n",
       "        [-1.1942037 , -0.6319522 ]], dtype=float32),\n",
       " array([[-0.4847255 ,  0.61144465],\n",
       "        [-0.45416445,  0.7111582 ],\n",
       "        [-0.8980478 ,  0.6922674 ],\n",
       "        ...,\n",
       "        [ 0.8187069 , -0.0659976 ],\n",
       "        [ 0.8264665 , -0.05013945],\n",
       "        [ 0.9322601 ,  0.14467111]], dtype=float32)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_output = encoder.predict(df_scaled)\n",
    "encoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ffe722d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean1</th>\n",
       "      <th>mean2</th>\n",
       "      <th>log_var1</th>\n",
       "      <th>log_var2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.497134</td>\n",
       "      <td>0.634390</td>\n",
       "      <td>-0.420586</td>\n",
       "      <td>-1.043792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.471024</td>\n",
       "      <td>0.651857</td>\n",
       "      <td>-0.430797</td>\n",
       "      <td>-1.046531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.875291</td>\n",
       "      <td>0.779905</td>\n",
       "      <td>-0.204578</td>\n",
       "      <td>-1.047681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.518749</td>\n",
       "      <td>0.620647</td>\n",
       "      <td>-0.412036</td>\n",
       "      <td>-1.041771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.481611</td>\n",
       "      <td>0.644075</td>\n",
       "      <td>-0.426752</td>\n",
       "      <td>-1.045181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8274</th>\n",
       "      <td>0.841200</td>\n",
       "      <td>-0.091978</td>\n",
       "      <td>-1.164395</td>\n",
       "      <td>-0.628234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8275</th>\n",
       "      <td>0.841200</td>\n",
       "      <td>-0.091978</td>\n",
       "      <td>-1.164395</td>\n",
       "      <td>-0.628234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8276</th>\n",
       "      <td>0.841200</td>\n",
       "      <td>-0.091978</td>\n",
       "      <td>-1.164395</td>\n",
       "      <td>-0.628234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8277</th>\n",
       "      <td>0.841200</td>\n",
       "      <td>-0.091978</td>\n",
       "      <td>-1.164395</td>\n",
       "      <td>-0.628234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8278</th>\n",
       "      <td>0.922010</td>\n",
       "      <td>-0.004497</td>\n",
       "      <td>-1.194204</td>\n",
       "      <td>-0.631952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8279 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         mean1     mean2  log_var1  log_var2\n",
       "0    -0.497134  0.634390 -0.420586 -1.043792\n",
       "1    -0.471024  0.651857 -0.430797 -1.046531\n",
       "2    -0.875291  0.779905 -0.204578 -1.047681\n",
       "3    -0.518749  0.620647 -0.412036 -1.041771\n",
       "4    -0.481611  0.644075 -0.426752 -1.045181\n",
       "...        ...       ...       ...       ...\n",
       "8274  0.841200 -0.091978 -1.164395 -0.628234\n",
       "8275  0.841200 -0.091978 -1.164395 -0.628234\n",
       "8276  0.841200 -0.091978 -1.164395 -0.628234\n",
       "8277  0.841200 -0.091978 -1.164395 -0.628234\n",
       "8278  0.922010 -0.004497 -1.194204 -0.631952\n",
       "\n",
       "[8279 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def feature_from_encoder(encoder_output):\n",
    "    # take mean and log_var as features\n",
    "    df_encoded_mean   = pd.DataFrame(encoder_output[0],columns=[\"mean1\",\"mean2\"])\n",
    "    df_encoded_logvar = pd.DataFrame(encoder_output[1],columns=[\"log_var1\",\"log_var2\"])\n",
    "    df_encoded        = df_encoded_mean.join(df_encoded_logvar)\n",
    "    return df_encoded\n",
    "\n",
    "df_encoded = feature_from_encoder(encoder_output)\n",
    "df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ac94f4f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IsolationForest(max_features=1, n_estimators=150, random_state=42)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VAE_IF=IsolationForest(n_estimators=150, \n",
    "                       max_samples ='auto', \n",
    "                       max_features=1,random_state=42)\n",
    "VAE_IF.fit(df_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "647dd300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.48525011, 0.4847171 , 0.58558559, 0.48906119, 0.48701446,\n",
       "       0.50837399, 0.65859537, 0.47622879, 0.48440507, 0.59527048,\n",
       "       0.48428325, 0.47782173, 0.52540531, 0.54494306, 0.46734691,\n",
       "       0.5168567 , 0.50935647, 0.51890465, 0.4884866 , 0.48272472])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VAE_IF_score = -1 * VAE_IF.score_samples(df_encoded)\n",
    "VAE_IF_score[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a4979f",
   "metadata": {},
   "source": [
    "# 4. Combination of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a666419c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    8279.000000\n",
       "mean        0.451213\n",
       "std         0.030114\n",
       "min         0.403969\n",
       "25%         0.428277\n",
       "50%         0.443766\n",
       "75%         0.471093\n",
       "max         0.599004\n",
       "Name: IF_score, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['IF_score'] = IF_score\n",
    "df['IF_score'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "15f0b013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    8279.000000\n",
       "mean        0.747234\n",
       "std         2.107643\n",
       "min         0.023347\n",
       "25%         0.194180\n",
       "50%         0.377740\n",
       "75%         0.776217\n",
       "max        97.686493\n",
       "Name: VAE_loss, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['VAE_loss'] = VAE_loss\n",
    "df['VAE_loss'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873cac85",
   "metadata": {},
   "source": [
    "Notice there is some extreme value in `VAE_loss`, which may affect our later visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "426fe229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.974172584272193"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['VAE_loss'].quantile(0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c4dd3e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    8279.000000\n",
       "mean        0.486291\n",
       "std         0.039233\n",
       "min         0.423997\n",
       "25%         0.458176\n",
       "50%         0.474988\n",
       "75%         0.508637\n",
       "max         0.715104\n",
       "Name: VAE_IF_score, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['VAE_IF_score'] = VAE_IF_score\n",
    "df['VAE_IF_score'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "77f67feb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DL_TRAFFIC_VOLUME</th>\n",
       "      <th>UL_TRAFFIC_VOLUME</th>\n",
       "      <th>Inter_X2_based_HO_prep</th>\n",
       "      <th>VoLTE_total_traffic</th>\n",
       "      <th>INTRA_FREQ_HO_SR_RATIO</th>\n",
       "      <th>RRC_SR_RATIO</th>\n",
       "      <th>CELL_AVAILABILITY_RATIO</th>\n",
       "      <th>RACH_Stp_Completion_SR_RATIO</th>\n",
       "      <th>Inter_RAT_HO_SR_UTRAN_SRVCC_RATIO</th>\n",
       "      <th>E_RAB_QCI1_DR_RATIO</th>\n",
       "      <th>...</th>\n",
       "      <th>E_UTRAN_Inter_Freq_HO_SR_RATIO</th>\n",
       "      <th>Inter_RAT_HO_SR_GERAN_SRVCC_RATIO</th>\n",
       "      <th>Inter_RAT_Total_HO_SR_RATIO</th>\n",
       "      <th>E_UTRAN_tot_HO_SR_inter_eNB_X2_RATIO</th>\n",
       "      <th>E_RAB_DR_RATIO</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>cell</th>\n",
       "      <th>IF_score</th>\n",
       "      <th>VAE_loss</th>\n",
       "      <th>VAE_IF_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.779737e+10</td>\n",
       "      <td>3.947172e+09</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4727.0</td>\n",
       "      <td>0.809859</td>\n",
       "      <td>0.992427</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.962688</td>\n",
       "      <td>0.576414</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.770642</td>\n",
       "      <td>0.963636</td>\n",
       "      <td>0.963636</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.001761</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.512958</td>\n",
       "      <td>0.954808</td>\n",
       "      <td>0.485250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.684898e+10</td>\n",
       "      <td>4.088752e+09</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3076.0</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.993288</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.973207</td>\n",
       "      <td>0.576414</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.002468</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.485098</td>\n",
       "      <td>0.733583</td>\n",
       "      <td>0.484717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.292677e+10</td>\n",
       "      <td>5.016897e+09</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3501.0</td>\n",
       "      <td>0.938356</td>\n",
       "      <td>0.994664</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.966330</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.931624</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.003077</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.536488</td>\n",
       "      <td>1.408995</td>\n",
       "      <td>0.585586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.021547e+10</td>\n",
       "      <td>5.139107e+09</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2275.0</td>\n",
       "      <td>0.860215</td>\n",
       "      <td>0.994819</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.943216</td>\n",
       "      <td>0.576414</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.816901</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.001721</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.509256</td>\n",
       "      <td>0.401727</td>\n",
       "      <td>0.489061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.082176e+10</td>\n",
       "      <td>4.250716e+09</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2178.0</td>\n",
       "      <td>0.840426</td>\n",
       "      <td>0.995952</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.936256</td>\n",
       "      <td>0.576414</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.794521</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.002213</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.489774</td>\n",
       "      <td>0.398755</td>\n",
       "      <td>0.487014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   DL_TRAFFIC_VOLUME  UL_TRAFFIC_VOLUME  Inter_X2_based_HO_prep  \\\n",
       "0       3.779737e+10       3.947172e+09                    15.0   \n",
       "1       3.684898e+10       4.088752e+09                     6.0   \n",
       "2       3.292677e+10       5.016897e+09                     8.0   \n",
       "3       3.021547e+10       5.139107e+09                     9.0   \n",
       "4       3.082176e+10       4.250716e+09                    17.0   \n",
       "\n",
       "   VoLTE_total_traffic  INTRA_FREQ_HO_SR_RATIO  RRC_SR_RATIO  \\\n",
       "0               4727.0                0.809859      0.992427   \n",
       "1               3076.0                0.886792      0.993288   \n",
       "2               3501.0                0.938356      0.994664   \n",
       "3               2275.0                0.860215      0.994819   \n",
       "4               2178.0                0.840426      0.995952   \n",
       "\n",
       "   CELL_AVAILABILITY_RATIO  RACH_Stp_Completion_SR_RATIO  \\\n",
       "0                      1.0                      0.962688   \n",
       "1                      1.0                      0.973207   \n",
       "2                      1.0                      0.966330   \n",
       "3                      1.0                      0.943216   \n",
       "4                      1.0                      0.936256   \n",
       "\n",
       "   Inter_RAT_HO_SR_UTRAN_SRVCC_RATIO  E_RAB_QCI1_DR_RATIO  ...  \\\n",
       "0                           0.576414             0.000000  ...   \n",
       "1                           0.576414             0.000000  ...   \n",
       "2                           0.000000             0.013889  ...   \n",
       "3                           0.576414             0.000000  ...   \n",
       "4                           0.576414             0.000000  ...   \n",
       "\n",
       "   E_UTRAN_Inter_Freq_HO_SR_RATIO  Inter_RAT_HO_SR_GERAN_SRVCC_RATIO  \\\n",
       "0                        0.770642                           0.963636   \n",
       "1                        0.842105                           1.000000   \n",
       "2                        0.931624                           1.000000   \n",
       "3                        0.816901                           0.947368   \n",
       "4                        0.794521                           1.000000   \n",
       "\n",
       "   Inter_RAT_Total_HO_SR_RATIO  E_UTRAN_tot_HO_SR_inter_eNB_X2_RATIO  \\\n",
       "0                     0.963636                              0.400000   \n",
       "1                     1.000000                              0.500000   \n",
       "2                     0.966667                              0.375000   \n",
       "3                     0.947368                              0.777778   \n",
       "4                     1.000000                              0.764706   \n",
       "\n",
       "   E_RAB_DR_RATIO  HOUR  cell  IF_score  VAE_loss  VAE_IF_score  \n",
       "0        0.001761     0     0  0.512958  0.954808      0.485250  \n",
       "1        0.002468     1     0  0.485098  0.733583      0.484717  \n",
       "2        0.003077     2     0  0.536488  1.408995      0.585586  \n",
       "3        0.001721     3     0  0.509256  0.401727      0.489061  \n",
       "4        0.002213     4     0  0.489774  0.398755      0.487014  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ad6fcc",
   "metadata": {},
   "source": [
    "# 5. Save Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6622f36e",
   "metadata": {},
   "source": [
    "## 5.1 Save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c3f2914d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model/IF.joblib']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save model\n",
    "dump(IF,\"model/IF.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "943ba5ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/VAE\\assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: model/Encoder\\assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: model/Decoder\\assets\n"
     ]
    }
   ],
   "source": [
    "vae.save(\"model/VAE\")\n",
    "encoder.save(\"model/Encoder\")\n",
    "decoder.save(\"model/Decoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6b164e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model/VAE_IF.joblib']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save model\n",
    "dump(VAE_IF,\"model/VAE_IF.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3f5b01",
   "metadata": {},
   "source": [
    "## 5.2 Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7c0e409a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/KPIs_with_metrics.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "320px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
