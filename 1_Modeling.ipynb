{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bec5f4de",
   "metadata": {},
   "source": [
    "# 0. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04f86b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "# Isolation Forest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# VAE\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.layers import Input, Dense, Lambda, Flatten, Reshape\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c0c0f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>cell_id</th>\n",
       "      <th>DL_TRAFFIC_VOLUME</th>\n",
       "      <th>UL_TRAFFIC_VOLUME</th>\n",
       "      <th>Inter_X2_based_HO_prep</th>\n",
       "      <th>VoLTE_total_traffic</th>\n",
       "      <th>INTRA_FREQ_HO_SR_RATIO</th>\n",
       "      <th>RRC_SR_RATIO</th>\n",
       "      <th>CELL_AVAILABILITY_RATIO</th>\n",
       "      <th>RACH_Stp_Completion_SR_RATIO</th>\n",
       "      <th>...</th>\n",
       "      <th>DCR_LTE_RATIO</th>\n",
       "      <th>CSSR_LTE_RATIO</th>\n",
       "      <th>LTE_INTER_ENODEB_HOSR_RATIO</th>\n",
       "      <th>E_UTRAN_Inter_Freq_HO_SR_RATIO</th>\n",
       "      <th>Inter_RAT_HO_SR_GERAN_SRVCC_RATIO</th>\n",
       "      <th>Inter_RAT_Total_HO_SR_RATIO</th>\n",
       "      <th>E_UTRAN_tot_HO_SR_inter_eNB_X2_RATIO</th>\n",
       "      <th>E_RAB_DR_RATIO</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>cell</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-05-09 00:00:00</td>\n",
       "      <td>2.226537e+17</td>\n",
       "      <td>3.779737e+10</td>\n",
       "      <td>3.947172e+09</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4727.0</td>\n",
       "      <td>0.809859</td>\n",
       "      <td>0.992427</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.962688</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001761</td>\n",
       "      <td>0.996041</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.770642</td>\n",
       "      <td>0.963636</td>\n",
       "      <td>0.963636</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.001761</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-05-09 01:00:00</td>\n",
       "      <td>2.226537e+17</td>\n",
       "      <td>3.684898e+10</td>\n",
       "      <td>4.088752e+09</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3076.0</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.993288</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.973207</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002468</td>\n",
       "      <td>0.995465</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.002468</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-05-09 02:00:00</td>\n",
       "      <td>2.226537e+17</td>\n",
       "      <td>3.292677e+10</td>\n",
       "      <td>5.016897e+09</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3501.0</td>\n",
       "      <td>0.938356</td>\n",
       "      <td>0.994664</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.966330</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003077</td>\n",
       "      <td>0.996044</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.931624</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.003077</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-05-09 03:00:00</td>\n",
       "      <td>2.226537e+17</td>\n",
       "      <td>3.021547e+10</td>\n",
       "      <td>5.139107e+09</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2275.0</td>\n",
       "      <td>0.860215</td>\n",
       "      <td>0.994819</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.943216</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001721</td>\n",
       "      <td>0.995920</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.816901</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.001721</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-05-09 04:00:00</td>\n",
       "      <td>2.226537e+17</td>\n",
       "      <td>3.082176e+10</td>\n",
       "      <td>4.250716e+09</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2178.0</td>\n",
       "      <td>0.840426</td>\n",
       "      <td>0.995952</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.936256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002213</td>\n",
       "      <td>0.995628</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.794521</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.002213</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 index       cell_id  DL_TRAFFIC_VOLUME  UL_TRAFFIC_VOLUME  \\\n",
       "0  2021-05-09 00:00:00  2.226537e+17       3.779737e+10       3.947172e+09   \n",
       "1  2021-05-09 01:00:00  2.226537e+17       3.684898e+10       4.088752e+09   \n",
       "2  2021-05-09 02:00:00  2.226537e+17       3.292677e+10       5.016897e+09   \n",
       "3  2021-05-09 03:00:00  2.226537e+17       3.021547e+10       5.139107e+09   \n",
       "4  2021-05-09 04:00:00  2.226537e+17       3.082176e+10       4.250716e+09   \n",
       "\n",
       "   Inter_X2_based_HO_prep  VoLTE_total_traffic  INTRA_FREQ_HO_SR_RATIO  \\\n",
       "0                    15.0               4727.0                0.809859   \n",
       "1                     6.0               3076.0                0.886792   \n",
       "2                     8.0               3501.0                0.938356   \n",
       "3                     9.0               2275.0                0.860215   \n",
       "4                    17.0               2178.0                0.840426   \n",
       "\n",
       "   RRC_SR_RATIO  CELL_AVAILABILITY_RATIO  RACH_Stp_Completion_SR_RATIO  ...  \\\n",
       "0      0.992427                      1.0                      0.962688  ...   \n",
       "1      0.993288                      1.0                      0.973207  ...   \n",
       "2      0.994664                      1.0                      0.966330  ...   \n",
       "3      0.994819                      1.0                      0.943216  ...   \n",
       "4      0.995952                      1.0                      0.936256  ...   \n",
       "\n",
       "   DCR_LTE_RATIO  CSSR_LTE_RATIO  LTE_INTER_ENODEB_HOSR_RATIO  \\\n",
       "0       0.001761        0.996041                     0.400000   \n",
       "1       0.002468        0.995465                     0.500000   \n",
       "2       0.003077        0.996044                     0.375000   \n",
       "3       0.001721        0.995920                     0.777778   \n",
       "4       0.002213        0.995628                     0.764706   \n",
       "\n",
       "   E_UTRAN_Inter_Freq_HO_SR_RATIO  Inter_RAT_HO_SR_GERAN_SRVCC_RATIO  \\\n",
       "0                        0.770642                           0.963636   \n",
       "1                        0.842105                           1.000000   \n",
       "2                        0.931624                           1.000000   \n",
       "3                        0.816901                           0.947368   \n",
       "4                        0.794521                           1.000000   \n",
       "\n",
       "   Inter_RAT_Total_HO_SR_RATIO  E_UTRAN_tot_HO_SR_inter_eNB_X2_RATIO  \\\n",
       "0                     0.963636                              0.400000   \n",
       "1                     1.000000                              0.500000   \n",
       "2                     0.966667                              0.375000   \n",
       "3                     0.947368                              0.777778   \n",
       "4                     1.000000                              0.764706   \n",
       "\n",
       "   E_RAB_DR_RATIO  HOUR  cell  \n",
       "0        0.001761     0     0  \n",
       "1        0.002468     1     0  \n",
       "2        0.003077     2     0  \n",
       "3        0.001721     3     0  \n",
       "4        0.002213     4     0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/cleaned_KPIs.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d75cb9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['cell_id','index'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8caf7790",
   "metadata": {},
   "source": [
    "# 1. Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "beba0e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "IF=IsolationForest(n_estimators=150, \n",
    "                      max_samples ='auto', \n",
    "                      max_features=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1c33a46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.52353176, 0.50734761, 0.55321262, 0.52291352, 0.50943034,\n",
       "       0.54142331, 0.53453815, 0.50166109, 0.5086878 , 0.49615564,\n",
       "       0.484272  , 0.49470025, 0.49741298, 0.51022317, 0.50678467,\n",
       "       0.50828956, 0.49764837, 0.48266657, 0.49900412, 0.48520034])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IF.fit(df)\n",
    "# score_samples = - score  \n",
    "IF_score = -1 * IF.score_samples(df)\n",
    "IF_score[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158f3a5b",
   "metadata": {},
   "source": [
    "# 2. VAE\n",
    "\n",
    "[keras - Variational AutoEncoder 官方代码范例(复杂)](https://keras.io/examples/generative/vae/)\n",
    "\n",
    "[keras - AE/VAE 相对简单的代码构建](https://blog.keras.io/building-autoencoders-in-keras.html)\n",
    "\n",
    "[keras - 中等程度AVE 但是有点乱](https://github.com/keras-team/keras/blob/2c8d1d03599cc03243bce8f07ed9c4a3d5f384f9/examples/variational_autoencoder.py)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[中文VAE理论+代码](https://blog.csdn.net/weixin_37737254/article/details/102920263)\n",
    "\n",
    "[keras - 函数式API](https://keras.io/guides/functional_api/)\n",
    "\n",
    "[keras - Conv1D](https://keras-zh.readthedocs.io/layers/convolutional/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3164441",
   "metadata": {},
   "source": [
    "## 2.1 Build model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d99a10",
   "metadata": {},
   "source": [
    "**(1) Standardize & Expand dimension**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "945523ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8279, 1, 20)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_expand = StandardScaler().fit_transform(df)\n",
    "df_expand = np.expand_dims(df,axis=1)\n",
    "df_expand.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646bc0fe",
   "metadata": {},
   "source": [
    "**(2) Define sampling function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "368be1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(args):\n",
    "    z_mean, z_log_sigma = args\n",
    "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim),\n",
    "                              mean=0., stddev=0.1)\n",
    "    return z_mean + K.exp(z_log_sigma) * epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8f45fb",
   "metadata": {},
   "source": [
    "**(3) Build Encoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9d03e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 1, 20)]      0           []                               \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 1, 32)        1952        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1, 32)        0           ['conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 32)           0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " z_mean (Dense)                 (None, 2)            66          ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " z_log_var (Dense)              (None, 2)            66          ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 2)            0           ['z_mean[0][0]',                 \n",
      "                                                                  'z_log_var[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,084\n",
      "Trainable params: 2,084\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "original_dim = df.shape[1]\n",
    "intermediate_dim = 32\n",
    "latent_dim = 2\n",
    "\n",
    "# encoder input\n",
    "inputs = keras.Input(shape=(1,original_dim))\n",
    "x = layers.Conv1D(filters=intermediate_dim, kernel_size=3, padding=\"same\", activation=\"relu\")(inputs)\n",
    "x = layers.Dropout(rate=0.2)(x)\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "# the output of encoder\n",
    "z_mean      = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_sigma = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "z           = layers.Lambda(sampling)([z_mean, z_log_sigma])\n",
    "\n",
    "# Create encoder\n",
    "encoder = keras.Model(inputs, [z_mean, z_log_sigma, z], name='encoder')\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a86f8c",
   "metadata": {},
   "source": [
    "**(4) Build Decoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12179934",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " z_sampling (InputLayer)     [(None, 2)]               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                96        \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 1, 32)             0         \n",
      "                                                                 \n",
      " conv1d_transpose (Conv1DTra  (None, 1, 32)            3104      \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1, 32)             0         \n",
      "                                                                 \n",
      " conv1d_transpose_1 (Conv1DT  (None, 1, 20)            1940      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,140\n",
      "Trainable params: 5,140\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create decoder\n",
    "latent_inputs = keras.Input(shape=(latent_dim,), name='z_sampling')\n",
    "x = layers.Dense(1*intermediate_dim, activation='relu')(latent_inputs)\n",
    "x = layers.Reshape((1,intermediate_dim))(x)\n",
    "x = layers.Conv1DTranspose(filters=intermediate_dim, kernel_size=3, padding=\"same\", activation=\"relu\")(x)\n",
    "x = layers.Dropout(rate=0.2)(x)\n",
    "outputs = layers.Conv1DTranspose(filters=original_dim, kernel_size=3, padding=\"same\", activation='sigmoid')(x)\n",
    "decoder = keras.Model(latent_inputs, outputs, name='decoder')\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adb2e38",
   "metadata": {},
   "source": [
    "**(5) Build Variational AutoEncoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55cd58bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate VAE model\n",
    "outputs = decoder(encoder(inputs)[2])\n",
    "vae = keras.Model(inputs, outputs, name='vae_mlp')\n",
    "\n",
    "w = 1/\n",
    "# Define Loss Function\n",
    "reconstruction_loss =  keras.losses.binary_crossentropy(inputs, outputs)\n",
    "kl_loss = -0.5 * K.sum(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma), axis=-1)\n",
    "vae_loss = K.mean(0*reconstruction_loss + kl_loss) #调整比例？？\n",
    "\n",
    "# Add loss function\n",
    "vae.add_loss(vae_loss)\n",
    "vae.compile(optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375b054b",
   "metadata": {},
   "source": [
    "ps: weight of kl_loss?    \n",
    "\n",
    "ref1.[theoretical insight](https://stats.stackexchange.com/questions/332179/how-to-weight-kld-loss-vs-reconstruction-loss-in-variational-auto-encoder)\n",
    "\n",
    "ref2.[a more specific example](https://stats.stackexchange.com/questions/341954/balancing-reconstruction-vs-kl-loss-variational-autoencoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4a3e53",
   "metadata": {},
   "source": [
    "**(6) Train model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96e63ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "33/33 [==============================] - 1s 3ms/step - loss: nan\n",
      "Epoch 2/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 3/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 4/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 5/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 6/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 7/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 8/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 9/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 10/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 11/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 12/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 13/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 14/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 15/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 16/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 17/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 18/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 19/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 20/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 21/200\n",
      "21/33 [==================>...........] - ETA: 0s - loss: nan"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-2ac6a6f91b4e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[1;31m#verbose=False\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m        )\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1214\u001b[0m                 _r=1):\n\u001b[0;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1217\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 910\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    940\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 942\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    943\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 3131\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   3132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3133\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1959\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1960\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1962\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    601\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 603\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    604\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    605\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 59\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "batch_size = 256\n",
    "\n",
    "\n",
    "# Train model\n",
    "vae.fit(df_expand, df_expand,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        #verbose=False\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "943ba5ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/2_VAE/cell0\\assets\n"
     ]
    }
   ],
   "source": [
    "vae.save(\"model/VAE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ade81d5",
   "metadata": {},
   "source": [
    "## 2.2 [Detect Anomaly](https://towardsdatascience.com/hands-on-anomaly-detection-with-variational-autoencoders-d4044672acd5)\n",
    "Detect anomaly by finding those who have a high reconstruction loss.\n",
    "\n",
    "\n",
    "Steps:\n",
    "1. Measure error between the original train (clean/normal) set and the output of the model, and generate an error vector representing the error term of each sample.\n",
    "\n",
    "2. Find a relatively extreme value on that vector to use as your error threshold.\n",
    "\n",
    "3. Run the model over the test or real data, in which anomalies are probably mixed with normal data.\n",
    "\n",
    "4. Measure the reconstruction error and mark samples that exhibit an error term higher than the error threshold as anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c710e729",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(original,reconstructed):\n",
    "    return np.mean(np.sum((original-reconstructed)**2,axis=1),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aaf1a17a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.44500221, 0.25751857, 0.49622781, 1.06377065, 0.98245546,\n",
       "       0.35493252, 0.26544952, 0.28748259, 0.48888827, 1.48943495,\n",
       "       1.59046277, 0.3092292 , 0.61331426, 0.77651233, 0.90566509,\n",
       "       1.12027929, 0.64347693, 1.09713459, 0.78433523, 0.72332917])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "x_train_pred = vae.predict(x_train)\n",
    "x_test_pred  = vae.predict(x_test)\n",
    "\n",
    "x_test_loss = mse(x_test,x_test_pred)\n",
    "x_test_loss[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4685c4d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01272717],\n",
       "       [0.00647947],\n",
       "       [0.01443421],\n",
       "       [0.03334698],\n",
       "       [0.03063724],\n",
       "       [0.00972569],\n",
       "       [0.00674376],\n",
       "       [0.00747799],\n",
       "       [0.01418963],\n",
       "       [0.0475318 ],\n",
       "       [0.05089844],\n",
       "       [0.00820268],\n",
       "       [0.01833599],\n",
       "       [0.0237744 ],\n",
       "       [0.02807828],\n",
       "       [0.03523007],\n",
       "       [0.01934113],\n",
       "       [0.0344588 ],\n",
       "       [0.02403509],\n",
       "       [0.02200212]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#just to show ... \n",
    "MinMaxScaler().fit_transform(np.array(x_test_loss).reshape(-1, 1))[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2806fe",
   "metadata": {},
   "source": [
    "# 3. VAE + IF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d583e5fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 2.2117567, -2.6360521],\n",
       "        [ 3.005916 , -2.505186 ],\n",
       "        [ 1.5189962, -3.5336614],\n",
       "        ...,\n",
       "        [-5.9262166,  7.3983345],\n",
       "        [-7.022243 ,  9.947377 ],\n",
       "        [-6.2559733,  8.537143 ]], dtype=float32),\n",
       " array([[-1.9449544, -2.0011637],\n",
       "        [-2.050037 , -2.2249632],\n",
       "        [-2.3688183, -2.2569823],\n",
       "        ...,\n",
       "        [-2.668743 , -0.8112968],\n",
       "        [-3.071959 , -1.2745733],\n",
       "        [-3.595646 , -1.815458 ]], dtype=float32),\n",
       " array([[ 2.2124903, -2.628674 ],\n",
       "        [ 3.0209   , -2.503102 ],\n",
       "        [ 1.5251638, -3.5338354],\n",
       "        ...,\n",
       "        [-5.9281125,  7.328612 ],\n",
       "        [-7.0222306,  9.924319 ],\n",
       "        [-6.254571 ,  8.52362  ]], dtype=float32)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# standarlized data \n",
    "df_cell = StandardScaler().fit_transform(df_cell)\n",
    "df_cell  = np.expand_dims(df_cell,axis=1)\n",
    "\n",
    "encoder_output = encoder.predict(df_cell)\n",
    "encoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ffe722d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean1</th>\n",
       "      <th>mean2</th>\n",
       "      <th>log_var1</th>\n",
       "      <th>log_var2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.211757</td>\n",
       "      <td>-2.636052</td>\n",
       "      <td>-1.944954</td>\n",
       "      <td>-2.001164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.005916</td>\n",
       "      <td>-2.505186</td>\n",
       "      <td>-2.050037</td>\n",
       "      <td>-2.224963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.518996</td>\n",
       "      <td>-3.533661</td>\n",
       "      <td>-2.368818</td>\n",
       "      <td>-2.256982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.402188</td>\n",
       "      <td>-3.422911</td>\n",
       "      <td>-2.038118</td>\n",
       "      <td>-2.176879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.999225</td>\n",
       "      <td>-1.698540</td>\n",
       "      <td>-1.908680</td>\n",
       "      <td>-2.162398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1650</th>\n",
       "      <td>-6.061464</td>\n",
       "      <td>8.394439</td>\n",
       "      <td>-2.240656</td>\n",
       "      <td>-0.697308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1651</th>\n",
       "      <td>-5.778695</td>\n",
       "      <td>8.521473</td>\n",
       "      <td>-2.654520</td>\n",
       "      <td>-0.971294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1652</th>\n",
       "      <td>-5.926217</td>\n",
       "      <td>7.398335</td>\n",
       "      <td>-2.668743</td>\n",
       "      <td>-0.811297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1653</th>\n",
       "      <td>-7.022243</td>\n",
       "      <td>9.947377</td>\n",
       "      <td>-3.071959</td>\n",
       "      <td>-1.274573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1654</th>\n",
       "      <td>-6.255973</td>\n",
       "      <td>8.537143</td>\n",
       "      <td>-3.595646</td>\n",
       "      <td>-1.815458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1655 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         mean1     mean2  log_var1  log_var2\n",
       "0     2.211757 -2.636052 -1.944954 -2.001164\n",
       "1     3.005916 -2.505186 -2.050037 -2.224963\n",
       "2     1.518996 -3.533661 -2.368818 -2.256982\n",
       "3     1.402188 -3.422911 -2.038118 -2.176879\n",
       "4     1.999225 -1.698540 -1.908680 -2.162398\n",
       "...        ...       ...       ...       ...\n",
       "1650 -6.061464  8.394439 -2.240656 -0.697308\n",
       "1651 -5.778695  8.521473 -2.654520 -0.971294\n",
       "1652 -5.926217  7.398335 -2.668743 -0.811297\n",
       "1653 -7.022243  9.947377 -3.071959 -1.274573\n",
       "1654 -6.255973  8.537143 -3.595646 -1.815458\n",
       "\n",
       "[1655 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def feature_from_encoder(encoder_output):\n",
    "    # take mean and log_var as features\n",
    "    df_encoded_mean   = pd.DataFrame(encoder_output[0],columns=[\"mean1\",\"mean2\"])\n",
    "    df_encoded_logvar = pd.DataFrame(encoder_output[1],columns=[\"log_var1\",\"log_var2\"])\n",
    "    df_encoded        = df_encoded_mean.join(df_encoded_logvar)\n",
    "    return df_encoded\n",
    "\n",
    "df_encoded = feature_from_encoder(encoder_output)\n",
    "df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac94f4f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IsolationForest(max_features=1, n_estimators=150)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VAE_IF=IsolationForest(n_estimators=150, \n",
    "                      max_samples ='auto', \n",
    "                      max_features=1)\n",
    "VAE_IF.fit(df_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "647dd300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.46744059, 0.48029628, 0.47513529, 0.45947107, 0.45043746,\n",
       "       0.46926745, 0.62673232, 0.41720654, 0.41796033, 0.42949577,\n",
       "       0.4537181 , 0.46111905, 0.43473572, 0.43110157, 0.44674073,\n",
       "       0.45667155, 0.42423758, 0.4510423 , 0.42525502, 0.42354986])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VAE_IF_score = -1 * VAE_IF.score_samples(df_encoded)\n",
    "VAE_IF_score[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a4979f",
   "metadata": {},
   "source": [
    "# 4. Combination of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a666419c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cell['IF_score'] = IF_score\n",
    "df_cell['IF_score'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ad6fcc",
   "metadata": {},
   "source": [
    "# 5.Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359cfeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anomalyPercent(model, df_test):\n",
    "    \"\"\"\n",
    "    Calculate the percentage of anomalies in the testset\n",
    "    \n",
    "    \"\"\"\n",
    "    df_pred = df_test.copy()\n",
    "    df_pred['anomaly'] = model.predict(df_test)\n",
    "    pct  = (df_pred['anomaly']==-1).sum()/len(df_test)\n",
    "    \n",
    "#     # map 1 -> 0, -1 -> 1\n",
    "#     reset_value = lambda x: 1 if x==-1 else 0\n",
    "#     df_test['anomaly'] = df_test['anomaly'].map(reset_value)\n",
    "    \n",
    "    return pct, df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b18458",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anomaly_visualization(df):\n",
    "    \"\"\"\n",
    "    Visualize anomalies in 2D/3D scatter plot\n",
    "    \n",
    "    INPUT\n",
    "    @df : a dataframe where the prediction result is in the 'anomaly' column\n",
    "    \n",
    "    \"\"\"\n",
    "    index = df.index\n",
    "    outlier_index = list(df[df['anomaly']==-1].index)\n",
    "    \n",
    "    # nomalize the metrics\n",
    "    X = StandardScaler().fit_transform(df.drop('anomaly',axis=1))\n",
    "    \n",
    "    # recude the dimension for visualization\n",
    "    X_3d = pd.DataFrame(PCA(3).fit_transform(X),index=index)\n",
    "    X_3d_outliers = X_3d.reindex(outlier_index)\n",
    "    X_2d = pd.DataFrame(PCA(2).fit_transform(X),index=index)\n",
    "    X_2d_outliers = X_2d.reindex(outlier_index)\n",
    "    \n",
    "    # plot\n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "    # 3D\n",
    "    ax1 = fig.add_subplot(121,  projection='3d')\n",
    "    ax1.scatter(X_3d.loc[:,0],X_3d.loc[:,1],X_3d.loc[:,2],\n",
    "                s=4,lw=1,label=\"inliers\",c=\"green\",alpha=0.5)\n",
    "    ax1.scatter(X_3d_outliers.loc[:,0], X_3d_outliers.loc[:,1], X_3d_outliers.loc[:,2],\n",
    "               s=60,marker=\"x\",lw=2,label=\"outliers\",c=\"red\")\n",
    "    ax1.legend()\n",
    "    ax1.set_title(\"Isolation Prediction (3D)\")\n",
    "    # 2D\n",
    "    ax2 = fig.add_subplot(133)\n",
    "    ax2.scatter(X_2d.loc[:,0],X_2d.loc[:,1],c=\"green\",\n",
    "                s=5,label=\"inliers\",alpha=0.8)\n",
    "    ax2.scatter(X_2d_outliers.iloc[:,0], X_2d_outliers.iloc[:,1],\n",
    "                s=60,marker=\"x\",lw=2,c='red',label=\"outliers\")\n",
    "    ax2.legend()\n",
    "    ax2.set_title(\"Isolation Prediction (2D)\")\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964e7dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(list_cells)):\n",
    "    # get the dataframe of a certain cell\n",
    "    df_c = list_cells[i].drop(['cell_id','index'], axis=1)\n",
    "    \n",
    "    # split train set and test set \n",
    "    df_train, df_test = train_test_split(df_c)\n",
    "    # train model \n",
    "    model.fit(df_train)\n",
    "    pct, df_pred = anomalyPercent(model, df_test)\n",
    "    print(\"=\"*75)\n",
    "    print(f\"cell id: {cell_ids[i]}\")\n",
    "    print(\"Percentage of outliers: %.3f \"%pct)\n",
    "    anomaly_visualization(df_pred)\n",
    "    print(\"\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "320px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
