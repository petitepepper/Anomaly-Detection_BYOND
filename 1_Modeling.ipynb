{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bec5f4de",
   "metadata": {},
   "source": [
    "# 0. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04f86b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "# Isolation Forest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# VAE\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.layers import Input, Dense, Lambda, Flatten, Reshape\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c0c0f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.2265366483183206e+17,\n",
       " 7.315874467898523e+16,\n",
       " 9.10621795573706e+16,\n",
       " 3.8447326973958944e+17,\n",
       " 4.262775046883192e+17]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_ids = pd.read_csv(\"data/cells_reduced/cell_ids.csv\",header=None)\n",
    "cell_ids = [x for lst in cell_ids.values.tolist() for x in lst]\n",
    "cell_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1c080c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cells = []\n",
    "for cell_id in cell_ids:\n",
    "    file_name = \"cell_\"+str(cell_id)+'.csv'\n",
    "    cells.append(pd.read_csv(f\"data/cells_reduced/{file_name}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "14021579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>cell_id</th>\n",
       "      <th>DL_TRAFFIC_VOLUME</th>\n",
       "      <th>UL_TRAFFIC_VOLUME</th>\n",
       "      <th>Inter_X2_based_HO_prep</th>\n",
       "      <th>VoLTE_total_traffic</th>\n",
       "      <th>INTRA_FREQ_HO_SR_RATIO</th>\n",
       "      <th>RRC_SR_RATIO</th>\n",
       "      <th>CELL_AVAILABILITY_RATIO</th>\n",
       "      <th>RACH_Stp_Completion_SR_RATIO</th>\n",
       "      <th>E_RAB_QCI1_DR_RATIO</th>\n",
       "      <th>DCR_LTE_RATIO</th>\n",
       "      <th>CSSR_LTE_RATIO</th>\n",
       "      <th>LTE_INTER_ENODEB_HOSR_RATIO</th>\n",
       "      <th>Inter_RAT_HO_SR_GERAN_SRVCC_RATIO</th>\n",
       "      <th>HOUR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-05-09 00:00:00</td>\n",
       "      <td>2.226537e+17</td>\n",
       "      <td>3.779737e+10</td>\n",
       "      <td>3.947172e+09</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4727.0</td>\n",
       "      <td>0.809859</td>\n",
       "      <td>0.992427</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.962688</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001761</td>\n",
       "      <td>0.996041</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.963636</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-05-09 01:00:00</td>\n",
       "      <td>2.226537e+17</td>\n",
       "      <td>3.684898e+10</td>\n",
       "      <td>4.088752e+09</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3076.0</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.993288</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.973207</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002468</td>\n",
       "      <td>0.995465</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-05-09 02:00:00</td>\n",
       "      <td>2.226537e+17</td>\n",
       "      <td>3.292677e+10</td>\n",
       "      <td>5.016897e+09</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3501.0</td>\n",
       "      <td>0.938356</td>\n",
       "      <td>0.994664</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.966330</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.003077</td>\n",
       "      <td>0.996044</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-05-09 03:00:00</td>\n",
       "      <td>2.226537e+17</td>\n",
       "      <td>3.021547e+10</td>\n",
       "      <td>5.139107e+09</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2275.0</td>\n",
       "      <td>0.860215</td>\n",
       "      <td>0.994819</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.943216</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001721</td>\n",
       "      <td>0.995920</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-05-09 04:00:00</td>\n",
       "      <td>2.226537e+17</td>\n",
       "      <td>3.082176e+10</td>\n",
       "      <td>4.250716e+09</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2178.0</td>\n",
       "      <td>0.840426</td>\n",
       "      <td>0.995952</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.936256</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002213</td>\n",
       "      <td>0.995628</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 index       cell_id  DL_TRAFFIC_VOLUME  UL_TRAFFIC_VOLUME  \\\n",
       "0  2021-05-09 00:00:00  2.226537e+17       3.779737e+10       3.947172e+09   \n",
       "1  2021-05-09 01:00:00  2.226537e+17       3.684898e+10       4.088752e+09   \n",
       "2  2021-05-09 02:00:00  2.226537e+17       3.292677e+10       5.016897e+09   \n",
       "3  2021-05-09 03:00:00  2.226537e+17       3.021547e+10       5.139107e+09   \n",
       "4  2021-05-09 04:00:00  2.226537e+17       3.082176e+10       4.250716e+09   \n",
       "\n",
       "   Inter_X2_based_HO_prep  VoLTE_total_traffic  INTRA_FREQ_HO_SR_RATIO  \\\n",
       "0                    15.0               4727.0                0.809859   \n",
       "1                     6.0               3076.0                0.886792   \n",
       "2                     8.0               3501.0                0.938356   \n",
       "3                     9.0               2275.0                0.860215   \n",
       "4                    17.0               2178.0                0.840426   \n",
       "\n",
       "   RRC_SR_RATIO  CELL_AVAILABILITY_RATIO  RACH_Stp_Completion_SR_RATIO  \\\n",
       "0      0.992427                      1.0                      0.962688   \n",
       "1      0.993288                      1.0                      0.973207   \n",
       "2      0.994664                      1.0                      0.966330   \n",
       "3      0.994819                      1.0                      0.943216   \n",
       "4      0.995952                      1.0                      0.936256   \n",
       "\n",
       "   E_RAB_QCI1_DR_RATIO  DCR_LTE_RATIO  CSSR_LTE_RATIO  \\\n",
       "0             0.000000       0.001761        0.996041   \n",
       "1             0.000000       0.002468        0.995465   \n",
       "2             0.013889       0.003077        0.996044   \n",
       "3             0.000000       0.001721        0.995920   \n",
       "4             0.000000       0.002213        0.995628   \n",
       "\n",
       "   LTE_INTER_ENODEB_HOSR_RATIO  Inter_RAT_HO_SR_GERAN_SRVCC_RATIO  HOUR  \n",
       "0                     0.400000                           0.963636     0  \n",
       "1                     0.500000                           1.000000     1  \n",
       "2                     0.375000                           1.000000     2  \n",
       "3                     0.777778                           0.947368     3  \n",
       "4                     0.764706                           1.000000     4  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cells[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d75cb9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cell = cells[0].drop(['cell_id','index'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8caf7790",
   "metadata": {},
   "source": [
    "# 1. Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "beba0e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "IF=IsolationForest(n_estimators=150, \n",
    "                      max_samples ='auto', \n",
    "                      max_features=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1c33a46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.48337733, 0.47235561, 0.52170271, 0.50062904, 0.4644712 ,\n",
       "       0.48547781, 0.49705167, 0.44710248, 0.44232739, 0.46360045,\n",
       "       0.45129292, 0.45863403, 0.47047797, 0.47552665, 0.47199786,\n",
       "       0.44972892, 0.44357685, 0.44221501, 0.43460012, 0.44040048])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IF.fit(df_cell)\n",
    "# score_samples = - score  \n",
    "IF_score = -1 * IF.score_samples(df_cell)\n",
    "IF_score[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c41c40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cell['IF_score'] = IF_score\n",
    "df_cell['IF_score'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158f3a5b",
   "metadata": {},
   "source": [
    "# 2. VAE\n",
    "\n",
    "[keras - Variational AutoEncoder 官方代码范例(复杂)](https://keras.io/examples/generative/vae/)\n",
    "\n",
    "[keras - AE/VAE 相对简单的代码构建](https://blog.keras.io/building-autoencoders-in-keras.html)\n",
    "\n",
    "[keras - 中等程度AVE 但是有点乱](https://github.com/keras-team/keras/blob/2c8d1d03599cc03243bce8f07ed9c4a3d5f384f9/examples/variational_autoencoder.py)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[中文VAE理论+代码](https://blog.csdn.net/weixin_37737254/article/details/102920263)\n",
    "\n",
    "[keras - 函数式API](https://keras.io/guides/functional_api/)\n",
    "\n",
    "[keras - Conv1D](https://keras-zh.readthedocs.io/layers/convolutional/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3164441",
   "metadata": {},
   "source": [
    "## 2.1 Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "945523ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "################  Standarlize & Split data  #################\n",
    "df_cell = cells[0].drop(['cell_id','index'],axis=1)\n",
    "x_train, x_test = train_test_split(df_cell)\n",
    "\n",
    "# Standarlized seperately to avoid data leak\n",
    "x_train = StandardScaler().fit_transform(x_train)\n",
    "x_test  = StandardScaler().fit_transform(x_test)\n",
    "x_train = np.expand_dims(x_train,axis=1)\n",
    "x_test  = np.expand_dims(x_test,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "368be1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "################ Define sampling function #################\n",
    "def sampling(args):\n",
    "    z_mean, z_log_sigma = args\n",
    "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim),\n",
    "                              mean=0., stddev=0.1)\n",
    "    return z_mean + K.exp(z_log_sigma) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9d03e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 1, 14)]      0           []                               \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 1, 32)        1376        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1, 32)        0           ['conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 32)           0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " z_mean (Dense)                 (None, 2)            66          ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " z_log_var (Dense)              (None, 2)            66          ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 2)            0           ['z_mean[0][0]',                 \n",
      "                                                                  'z_log_var[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,508\n",
      "Trainable params: 1,508\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "################ Build Encoder #################\n",
    "original_dim = df_cell.shape[1]\n",
    "intermediate_dim = 32\n",
    "latent_dim = 2\n",
    "\n",
    "# encoder input\n",
    "inputs = keras.Input(shape=(1,original_dim))\n",
    "x = layers.Conv1D(filters=intermediate_dim, kernel_size=3, padding=\"same\", activation=\"relu\")(inputs)\n",
    "x = layers.Dropout(rate=0.2)(x)\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "# the output of encoder\n",
    "z_mean      = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_sigma = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "z           = layers.Lambda(sampling)([z_mean, z_log_sigma])\n",
    "\n",
    "# Create encoder\n",
    "encoder = keras.Model(inputs, [z_mean, z_log_sigma, z], name='encoder')\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12179934",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " z_sampling (InputLayer)     [(None, 2)]               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                96        \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 1, 32)             0         \n",
      "                                                                 \n",
      " conv1d_transpose (Conv1DTra  (None, 1, 32)            3104      \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1, 32)             0         \n",
      "                                                                 \n",
      " conv1d_transpose_1 (Conv1DT  (None, 1, 14)            1358      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,558\n",
      "Trainable params: 4,558\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "################ Build Decoder #################\n",
    "\n",
    "# Create decoder\n",
    "latent_inputs = keras.Input(shape=(latent_dim,), name='z_sampling')\n",
    "x = layers.Dense(1*intermediate_dim, activation='relu')(latent_inputs)\n",
    "x = layers.Reshape((1,intermediate_dim))(x)\n",
    "x = layers.Conv1DTranspose(filters=intermediate_dim, kernel_size=3, padding=\"same\", activation=\"relu\")(x)\n",
    "x = layers.Dropout(rate=0.2)(x)\n",
    "outputs = layers.Conv1DTranspose(filters=original_dim, kernel_size=3, padding=\"same\", activation='sigmoid')(x)\n",
    "decoder = keras.Model(latent_inputs, outputs, name='decoder')\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55cd58bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "################ Instantiate VAE model ################# \n",
    "outputs = decoder(encoder(inputs)[2])\n",
    "vae = keras.Model(inputs, outputs, name='vae_mlp')\n",
    "\n",
    "################     Loss Function      ################# \n",
    "reconstruction_loss = keras.losses.mean_squared_error(inputs, outputs)\n",
    "# reconstruction_loss *= original_dim\n",
    "kl_loss = 1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma)\n",
    "kl_loss = K.sum(kl_loss, axis=-1)\n",
    "kl_loss *= -0.5\n",
    "vae_loss = K.mean(reconstruction_loss + 0.0001*kl_loss) #调整比例？？\n",
    "vae.add_loss(vae_loss)\n",
    "vae.compile(optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375b054b",
   "metadata": {},
   "source": [
    "ps: weight of kl_loss?    \n",
    "\n",
    "ref1.[theoretical insight](https://stats.stackexchange.com/questions/332179/how-to-weight-kld-loss-vs-reconstruction-loss-in-variational-auto-encoder)\n",
    "\n",
    "ref2.[a more specific example](https://stats.stackexchange.com/questions/341954/balancing-reconstruction-vs-kl-loss-variational-autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96e63ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "39/39 [==============================] - 1s 9ms/step - loss: 1.2259 - val_loss: 1.1834\n",
      "Epoch 2/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 1.0984 - val_loss: 1.0088\n",
      "Epoch 3/100\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.9944 - val_loss: 0.9783\n",
      "Epoch 4/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.9618 - val_loss: 0.9419\n",
      "Epoch 5/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.9313 - val_loss: 0.9158\n",
      "Epoch 6/100\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.9155 - val_loss: 0.9040\n",
      "Epoch 7/100\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.9049 - val_loss: 0.8929\n",
      "Epoch 8/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8979 - val_loss: 0.8831\n",
      "Epoch 9/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8886 - val_loss: 0.8755\n",
      "Epoch 10/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8817 - val_loss: 0.8713\n",
      "Epoch 11/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8830 - val_loss: 0.8670\n",
      "Epoch 12/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8760 - val_loss: 0.8650\n",
      "Epoch 13/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8748 - val_loss: 0.8623\n",
      "Epoch 14/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8695 - val_loss: 0.8599\n",
      "Epoch 15/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8664 - val_loss: 0.8583\n",
      "Epoch 16/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8672 - val_loss: 0.8570\n",
      "Epoch 17/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8626 - val_loss: 0.8551\n",
      "Epoch 18/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8622 - val_loss: 0.8540\n",
      "Epoch 19/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8616 - val_loss: 0.8530\n",
      "Epoch 20/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8592 - val_loss: 0.8527\n",
      "Epoch 21/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8611 - val_loss: 0.8516\n",
      "Epoch 22/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8580 - val_loss: 0.8507\n",
      "Epoch 23/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8575 - val_loss: 0.8502\n",
      "Epoch 24/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8578 - val_loss: 0.8496\n",
      "Epoch 25/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8535 - val_loss: 0.8488\n",
      "Epoch 26/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8746 - val_loss: 0.8471\n",
      "Epoch 27/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8528 - val_loss: 0.8454\n",
      "Epoch 28/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8537 - val_loss: 0.8451\n",
      "Epoch 29/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8550 - val_loss: 0.8439\n",
      "Epoch 30/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8548 - val_loss: 0.8432\n",
      "Epoch 31/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8506 - val_loss: 0.8416\n",
      "Epoch 32/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8507 - val_loss: 0.8425\n",
      "Epoch 33/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8505 - val_loss: 0.8413\n",
      "Epoch 34/100\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.8501 - val_loss: 0.8404\n",
      "Epoch 35/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8445 - val_loss: 0.8380\n",
      "Epoch 36/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8463 - val_loss: 0.8357\n",
      "Epoch 37/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8469 - val_loss: 0.8355\n",
      "Epoch 38/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.8412 - val_loss: 0.8340\n",
      "Epoch 39/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8448 - val_loss: 0.8321\n",
      "Epoch 40/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8449 - val_loss: 0.8317\n",
      "Epoch 41/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.8398 - val_loss: 0.8312\n",
      "Epoch 42/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8442 - val_loss: 0.8306\n",
      "Epoch 43/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8417 - val_loss: 0.8291\n",
      "Epoch 44/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8387 - val_loss: 0.8298\n",
      "Epoch 45/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8384 - val_loss: 0.8282\n",
      "Epoch 46/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8357 - val_loss: 0.8283\n",
      "Epoch 47/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8396 - val_loss: 0.8276\n",
      "Epoch 48/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8350 - val_loss: 0.8274\n",
      "Epoch 49/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8360 - val_loss: 0.8275\n",
      "Epoch 50/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8392 - val_loss: 0.8267\n",
      "Epoch 51/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8360 - val_loss: 0.8262\n",
      "Epoch 52/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8378 - val_loss: 0.8258\n",
      "Epoch 53/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8348 - val_loss: 0.8255\n",
      "Epoch 54/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8324 - val_loss: 0.8260\n",
      "Epoch 55/100\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.8303 - val_loss: 0.8240\n",
      "Epoch 56/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8308 - val_loss: 0.8233\n",
      "Epoch 57/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8298 - val_loss: 0.8228\n",
      "Epoch 58/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8312 - val_loss: 0.8223\n",
      "Epoch 59/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8286 - val_loss: 0.8228\n",
      "Epoch 60/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8287 - val_loss: 0.8220\n",
      "Epoch 61/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8327 - val_loss: 0.8221\n",
      "Epoch 62/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8286 - val_loss: 0.8216\n",
      "Epoch 63/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8262 - val_loss: 0.8208\n",
      "Epoch 64/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8291 - val_loss: 0.8211\n",
      "Epoch 65/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8274 - val_loss: 0.8210\n",
      "Epoch 66/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8256 - val_loss: 0.8197\n",
      "Epoch 67/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8251 - val_loss: 0.8196\n",
      "Epoch 68/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8256 - val_loss: 0.8198\n",
      "Epoch 69/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8247 - val_loss: 0.8180\n",
      "Epoch 70/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8251 - val_loss: 0.8172\n",
      "Epoch 71/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8232 - val_loss: 0.8174\n",
      "Epoch 72/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8231 - val_loss: 0.8163\n",
      "Epoch 73/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8238 - val_loss: 0.8165\n",
      "Epoch 74/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8218 - val_loss: 0.8164\n",
      "Epoch 75/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8251 - val_loss: 0.8165\n",
      "Epoch 76/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8205 - val_loss: 0.8157\n",
      "Epoch 77/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8415 - val_loss: 0.8169\n",
      "Epoch 78/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8237 - val_loss: 0.8181\n",
      "Epoch 79/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8206 - val_loss: 0.8177\n",
      "Epoch 80/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8201 - val_loss: 0.8162\n",
      "Epoch 81/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8193 - val_loss: 0.8173\n",
      "Epoch 82/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8195 - val_loss: 0.8167\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8201 - val_loss: 0.8182\n",
      "Epoch 84/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8178 - val_loss: 0.8177\n",
      "Epoch 85/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8208 - val_loss: 0.8162\n",
      "Epoch 86/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8208 - val_loss: 0.8155\n",
      "Epoch 87/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8215 - val_loss: 0.8160\n",
      "Epoch 88/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8195 - val_loss: 0.8146\n",
      "Epoch 89/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8219 - val_loss: 0.8148\n",
      "Epoch 90/100\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.8156 - val_loss: 0.8130\n",
      "Epoch 91/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8183 - val_loss: 0.8115\n",
      "Epoch 92/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8173 - val_loss: 0.8133\n",
      "Epoch 93/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8207 - val_loss: 0.8132\n",
      "Epoch 94/100\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.8158 - val_loss: 0.8133\n",
      "Epoch 95/100\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.8150 - val_loss: 0.8136\n",
      "Epoch 96/100\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.8164 - val_loss: 0.8138\n",
      "Epoch 97/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8154 - val_loss: 0.8142\n",
      "Epoch 98/100\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.8147 - val_loss: 0.8123\n",
      "Epoch 99/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8152 - val_loss: 0.8128\n",
      "Epoch 100/100\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.8151 - val_loss: 0.8122\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2090fea4f08>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "vae.fit(x_train, x_train,\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "943ba5ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/2_VAE/cell0\\assets\n"
     ]
    }
   ],
   "source": [
    "vae.save(\"model/2_VAE/cell0/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ade81d5",
   "metadata": {},
   "source": [
    "## 2.2 [Detect Anomaly](https://towardsdatascience.com/hands-on-anomaly-detection-with-variational-autoencoders-d4044672acd5)\n",
    "Detect anomaly by finding those who have a high reconstruction loss.\n",
    "\n",
    "\n",
    "Steps:\n",
    "1. Measure error between the original train (clean/normal) set and the output of the model, and generate an error vector representing the error term of each sample.\n",
    "\n",
    "2. Find a relatively extreme value on that vector to use as your error threshold.\n",
    "\n",
    "3. Run the model over the test or real data, in which anomalies are probably mixed with normal data.\n",
    "\n",
    "4. Measure the reconstruction error and mark samples that exhibit an error term higher than the error threshold as anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c710e729",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(original,reconstructed):\n",
    "    return np.mean(np.sum((original-reconstructed)**2,axis=1),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aaf1a17a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.44500221, 0.25751857, 0.49622781, 1.06377065, 0.98245546,\n",
       "       0.35493252, 0.26544952, 0.28748259, 0.48888827, 1.48943495,\n",
       "       1.59046277, 0.3092292 , 0.61331426, 0.77651233, 0.90566509,\n",
       "       1.12027929, 0.64347693, 1.09713459, 0.78433523, 0.72332917])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "x_train_pred = vae.predict(x_train)\n",
    "x_test_pred  = vae.predict(x_test)\n",
    "\n",
    "x_test_loss = mse(x_test,x_test_pred)\n",
    "x_test_loss[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4685c4d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01272717],\n",
       "       [0.00647947],\n",
       "       [0.01443421],\n",
       "       [0.03334698],\n",
       "       [0.03063724],\n",
       "       [0.00972569],\n",
       "       [0.00674376],\n",
       "       [0.00747799],\n",
       "       [0.01418963],\n",
       "       [0.0475318 ],\n",
       "       [0.05089844],\n",
       "       [0.00820268],\n",
       "       [0.01833599],\n",
       "       [0.0237744 ],\n",
       "       [0.02807828],\n",
       "       [0.03523007],\n",
       "       [0.01934113],\n",
       "       [0.0344588 ],\n",
       "       [0.02403509],\n",
       "       [0.02200212]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#just to show ... \n",
    "MinMaxScaler().fit_transform(np.array(x_test_loss).reshape(-1, 1))[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2806fe",
   "metadata": {},
   "source": [
    "# 3. VAE + IF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d583e5fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 2.2117567, -2.6360521],\n",
       "        [ 3.005916 , -2.505186 ],\n",
       "        [ 1.5189962, -3.5336614],\n",
       "        ...,\n",
       "        [-5.9262166,  7.3983345],\n",
       "        [-7.022243 ,  9.947377 ],\n",
       "        [-6.2559733,  8.537143 ]], dtype=float32),\n",
       " array([[-1.9449544, -2.0011637],\n",
       "        [-2.050037 , -2.2249632],\n",
       "        [-2.3688183, -2.2569823],\n",
       "        ...,\n",
       "        [-2.668743 , -0.8112968],\n",
       "        [-3.071959 , -1.2745733],\n",
       "        [-3.595646 , -1.815458 ]], dtype=float32),\n",
       " array([[ 2.2124903, -2.628674 ],\n",
       "        [ 3.0209   , -2.503102 ],\n",
       "        [ 1.5251638, -3.5338354],\n",
       "        ...,\n",
       "        [-5.9281125,  7.328612 ],\n",
       "        [-7.0222306,  9.924319 ],\n",
       "        [-6.254571 ,  8.52362  ]], dtype=float32)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# standarlized data \n",
    "df_cell = StandardScaler().fit_transform(df_cell)\n",
    "df_cell  = np.expand_dims(df_cell,axis=1)\n",
    "\n",
    "encoder_output = encoder.predict(df_cell)\n",
    "encoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ffe722d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean1</th>\n",
       "      <th>mean2</th>\n",
       "      <th>log_var1</th>\n",
       "      <th>log_var2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.211757</td>\n",
       "      <td>-2.636052</td>\n",
       "      <td>-1.944954</td>\n",
       "      <td>-2.001164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.005916</td>\n",
       "      <td>-2.505186</td>\n",
       "      <td>-2.050037</td>\n",
       "      <td>-2.224963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.518996</td>\n",
       "      <td>-3.533661</td>\n",
       "      <td>-2.368818</td>\n",
       "      <td>-2.256982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.402188</td>\n",
       "      <td>-3.422911</td>\n",
       "      <td>-2.038118</td>\n",
       "      <td>-2.176879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.999225</td>\n",
       "      <td>-1.698540</td>\n",
       "      <td>-1.908680</td>\n",
       "      <td>-2.162398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1650</th>\n",
       "      <td>-6.061464</td>\n",
       "      <td>8.394439</td>\n",
       "      <td>-2.240656</td>\n",
       "      <td>-0.697308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1651</th>\n",
       "      <td>-5.778695</td>\n",
       "      <td>8.521473</td>\n",
       "      <td>-2.654520</td>\n",
       "      <td>-0.971294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1652</th>\n",
       "      <td>-5.926217</td>\n",
       "      <td>7.398335</td>\n",
       "      <td>-2.668743</td>\n",
       "      <td>-0.811297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1653</th>\n",
       "      <td>-7.022243</td>\n",
       "      <td>9.947377</td>\n",
       "      <td>-3.071959</td>\n",
       "      <td>-1.274573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1654</th>\n",
       "      <td>-6.255973</td>\n",
       "      <td>8.537143</td>\n",
       "      <td>-3.595646</td>\n",
       "      <td>-1.815458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1655 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         mean1     mean2  log_var1  log_var2\n",
       "0     2.211757 -2.636052 -1.944954 -2.001164\n",
       "1     3.005916 -2.505186 -2.050037 -2.224963\n",
       "2     1.518996 -3.533661 -2.368818 -2.256982\n",
       "3     1.402188 -3.422911 -2.038118 -2.176879\n",
       "4     1.999225 -1.698540 -1.908680 -2.162398\n",
       "...        ...       ...       ...       ...\n",
       "1650 -6.061464  8.394439 -2.240656 -0.697308\n",
       "1651 -5.778695  8.521473 -2.654520 -0.971294\n",
       "1652 -5.926217  7.398335 -2.668743 -0.811297\n",
       "1653 -7.022243  9.947377 -3.071959 -1.274573\n",
       "1654 -6.255973  8.537143 -3.595646 -1.815458\n",
       "\n",
       "[1655 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def feature_from_encoder(encoder_output):\n",
    "    # take mean and log_var as features\n",
    "    df_encoded_mean   = pd.DataFrame(encoder_output[0],columns=[\"mean1\",\"mean2\"])\n",
    "    df_encoded_logvar = pd.DataFrame(encoder_output[1],columns=[\"log_var1\",\"log_var2\"])\n",
    "    df_encoded        = df_encoded_mean.join(df_encoded_logvar)\n",
    "    return df_encoded\n",
    "\n",
    "df_encoded = feature_from_encoder(encoder_output)\n",
    "df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac94f4f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IsolationForest(max_features=1, n_estimators=150)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VAE_IF=IsolationForest(n_estimators=150, \n",
    "                      max_samples ='auto', \n",
    "                      max_features=1)\n",
    "VAE_IF.fit(df_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "647dd300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.46744059, 0.48029628, 0.47513529, 0.45947107, 0.45043746,\n",
       "       0.46926745, 0.62673232, 0.41720654, 0.41796033, 0.42949577,\n",
       "       0.4537181 , 0.46111905, 0.43473572, 0.43110157, 0.44674073,\n",
       "       0.45667155, 0.42423758, 0.4510423 , 0.42525502, 0.42354986])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VAE_IF_score = -1 * VAE_IF.score_samples(df_encoded)\n",
    "VAE_IF_score[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ad6fcc",
   "metadata": {},
   "source": [
    "# 4.Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359cfeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anomalyPercent(model, df_test):\n",
    "    \"\"\"\n",
    "    Calculate the percentage of anomalies in the testset\n",
    "    \n",
    "    \"\"\"\n",
    "    df_pred = df_test.copy()\n",
    "    df_pred['anomaly'] = model.predict(df_test)\n",
    "    pct  = (df_pred['anomaly']==-1).sum()/len(df_test)\n",
    "    \n",
    "#     # map 1 -> 0, -1 -> 1\n",
    "#     reset_value = lambda x: 1 if x==-1 else 0\n",
    "#     df_test['anomaly'] = df_test['anomaly'].map(reset_value)\n",
    "    \n",
    "    return pct, df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b18458",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anomaly_visualization(df):\n",
    "    \"\"\"\n",
    "    Visualize anomalies in 2D/3D scatter plot\n",
    "    \n",
    "    INPUT\n",
    "    @df : a dataframe where the prediction result is in the 'anomaly' column\n",
    "    \n",
    "    \"\"\"\n",
    "    index = df.index\n",
    "    outlier_index = list(df[df['anomaly']==-1].index)\n",
    "    \n",
    "    # nomalize the metrics\n",
    "    X = StandardScaler().fit_transform(df.drop('anomaly',axis=1))\n",
    "    \n",
    "    # recude the dimension for visualization\n",
    "    X_3d = pd.DataFrame(PCA(3).fit_transform(X),index=index)\n",
    "    X_3d_outliers = X_3d.reindex(outlier_index)\n",
    "    X_2d = pd.DataFrame(PCA(2).fit_transform(X),index=index)\n",
    "    X_2d_outliers = X_2d.reindex(outlier_index)\n",
    "    \n",
    "    # plot\n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "    # 3D\n",
    "    ax1 = fig.add_subplot(121,  projection='3d')\n",
    "    ax1.scatter(X_3d.loc[:,0],X_3d.loc[:,1],X_3d.loc[:,2],\n",
    "                s=4,lw=1,label=\"inliers\",c=\"green\",alpha=0.5)\n",
    "    ax1.scatter(X_3d_outliers.loc[:,0], X_3d_outliers.loc[:,1], X_3d_outliers.loc[:,2],\n",
    "               s=60,marker=\"x\",lw=2,label=\"outliers\",c=\"red\")\n",
    "    ax1.legend()\n",
    "    ax1.set_title(\"Isolation Prediction (3D)\")\n",
    "    # 2D\n",
    "    ax2 = fig.add_subplot(133)\n",
    "    ax2.scatter(X_2d.loc[:,0],X_2d.loc[:,1],c=\"green\",\n",
    "                s=5,label=\"inliers\",alpha=0.8)\n",
    "    ax2.scatter(X_2d_outliers.iloc[:,0], X_2d_outliers.iloc[:,1],\n",
    "                s=60,marker=\"x\",lw=2,c='red',label=\"outliers\")\n",
    "    ax2.legend()\n",
    "    ax2.set_title(\"Isolation Prediction (2D)\")\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964e7dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(list_cells)):\n",
    "    # get the dataframe of a certain cell\n",
    "    df_c = list_cells[i].drop(['cell_id','index'], axis=1)\n",
    "    \n",
    "    # split train set and test set \n",
    "    df_train, df_test = train_test_split(df_c)\n",
    "    # train model \n",
    "    model.fit(df_train)\n",
    "    pct, df_pred = anomalyPercent(model, df_test)\n",
    "    print(\"=\"*75)\n",
    "    print(f\"cell id: {cell_ids[i]}\")\n",
    "    print(\"Percentage of outliers: %.3f \"%pct)\n",
    "    anomaly_visualization(df_pred)\n",
    "    print(\"\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "320px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
